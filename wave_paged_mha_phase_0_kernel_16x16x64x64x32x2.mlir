#map = affine_map<()[s0] -> (s0 + 1)>
#map1 = affine_map<()[s0] -> (s0 ceildiv 64)>
#map2 = affine_map<()[s0] -> (s0 * 8 - (s0 floordiv 8) * 64)>
#map3 = affine_map<()[s0] -> ((s0 floordiv 8) mod 64)>
#map4 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 8) floordiv 64) * 64 + 8)>
#map5 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 16) floordiv 64) * 64 + 16)>
#map6 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 24) floordiv 64) * 64 + 24)>
#map7 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 32) floordiv 64) * 64 + 32)>
#map8 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 40) floordiv 64) * 64 + 40)>
#map9 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 48) floordiv 64) * 64 + 48)>
#map10 = affine_map<()[s0] -> (s0 floordiv 8 - ((s0 floordiv 8 + 56) floordiv 64) * 64 + 56)>
#map11 = affine_map<()[s0] -> (s0 mod 64)>
#map12 = affine_map<()[s0, s1, s2] -> (s0 + s1 + s2)>
#map13 = affine_map<()[s0, s1, s2, s3] -> (s0 + s1 * 64 + s2 + s3 - (s0 floordiv 64) * 64)>
#map14 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + (s0 floordiv 8) mod 64)>
#map15 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 56) floordiv 64) * 64 + 56)>
#map16 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 48) floordiv 64) * 64 + 48)>
#map17 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 40) floordiv 64) * 64 + 40)>
#map18 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 32) floordiv 64) * 64 + 32)>
#map19 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 24) floordiv 64) * 64 + 24)>
#map20 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 16) floordiv 64) * 64 + 16)>
#map21 = affine_map<()[s0, s1, s2, s3] -> (s1 * 64 + s2 + s3 + s0 floordiv 8 - ((s0 floordiv 8 + 8) floordiv 64) * 64 + 8)>
#translation = #iree_codegen.translation_info<pipeline = None workgroup_size = [64, 1, 1] subgroup_size = 64>
module attributes {transform.with_named_sequence} {
  stream.executable private @phase_0 {
    stream.executable.export public @phase_0 workgroups(%arg0: index, %arg1: index, %arg2: index) -> (index, index, index) {
      %c16 = arith.constant 16 : index
      %c8 = arith.constant 8 : index
      stream.return %arg2, %c16, %c8 : index, index, index
    }
    builtin.module {
      func.func @phase_0(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: !stream.binding, %arg3: !stream.binding, %arg4: !stream.binding, %arg5: !stream.binding, %arg6: !stream.binding, %arg7: index, %arg8: index, %arg9: index) attributes {translation_info = #translation} {
        %c63 = arith.constant 63 : index
        %c62 = arith.constant 62 : index
        %c61 = arith.constant 61 : index
        %c59 = arith.constant 59 : index
        %c58 = arith.constant 58 : index
        %c57 = arith.constant 57 : index
        %c55 = arith.constant 55 : index
        %c54 = arith.constant 54 : index
        %c53 = arith.constant 53 : index
        %c51 = arith.constant 51 : index
        %c50 = arith.constant 50 : index
        %c49 = arith.constant 49 : index
        %c47 = arith.constant 47 : index
        %c46 = arith.constant 46 : index
        %c45 = arith.constant 45 : index
        %c43 = arith.constant 43 : index
        %c42 = arith.constant 42 : index
        %c41 = arith.constant 41 : index
        %c39 = arith.constant 39 : index
        %c38 = arith.constant 38 : index
        %c37 = arith.constant 37 : index
        %c35 = arith.constant 35 : index
        %c34 = arith.constant 34 : index
        %c33 = arith.constant 33 : index
        %c31 = arith.constant 31 : index
        %c30 = arith.constant 30 : index
        %c29 = arith.constant 29 : index
        %c27 = arith.constant 27 : index
        %c26 = arith.constant 26 : index
        %c25 = arith.constant 25 : index
        %c23 = arith.constant 23 : index
        %c22 = arith.constant 22 : index
        %c21 = arith.constant 21 : index
        %c19 = arith.constant 19 : index
        %c18 = arith.constant 18 : index
        %c17 = arith.constant 17 : index
        %c15 = arith.constant 15 : index
        %c14 = arith.constant 14 : index
        %c13 = arith.constant 13 : index
        %c11 = arith.constant 11 : index
        %c10 = arith.constant 10 : index
        %c9 = arith.constant 9 : index
        %c7 = arith.constant 7 : index
        %c6 = arith.constant 6 : index
        %c5 = arith.constant 5 : index
        %c3 = arith.constant 3 : index
        %c2 = arith.constant 2 : index
        %cst = arith.constant dense<0.000000e+00> : vector<1xf16>
        %cst_0 = arith.constant dense<0.000000e+00> : vector<8xf16>
        %cst_1 = arith.constant dense<0> : vector<1xi32>
        %cst_2 = arith.constant dense<8> : vector<1xindex>
        %cst_3 = arith.constant dense<1.000000e+00> : vector<1xf32>
        %c32_i32 = arith.constant 32 : i32
        %c16_i32 = arith.constant 16 : i32
        %c8_i32 = arith.constant 8 : i32
        %c4_i32 = arith.constant 4 : i32
        %c2_i32 = arith.constant 2 : i32
        %c64_i32 = arith.constant 64 : i32
        %c1_i32 = arith.constant 1 : i32
        %c60 = arith.constant 60 : index
        %c56 = arith.constant 56 : index
        %c52 = arith.constant 52 : index
        %c48 = arith.constant 48 : index
        %c44 = arith.constant 44 : index
        %c40 = arith.constant 40 : index
        %c36 = arith.constant 36 : index
        %c32 = arith.constant 32 : index
        %c28 = arith.constant 28 : index
        %c24 = arith.constant 24 : index
        %c20 = arith.constant 20 : index
        %c16 = arith.constant 16 : index
        %c12 = arith.constant 12 : index
        %c4 = arith.constant 4 : index
        %c8704 = arith.constant 8704 : index
        %c8 = arith.constant 8 : index
        %c1 = arith.constant 1 : index
        %c0 = arith.constant 0 : index
        %cst_4 = arith.constant dense<0.000000e+00> : vector<1xf32>
        %cst_5 = arith.constant dense<-1.000000e+06> : vector<1xf32>
        %cst_6 = arith.constant dense<0.180336878> : vector<1xf32>
        %block_id_x = gpu.block_id  x
        %block_id_y = gpu.block_id  y upper_bound 16
        %block_id_z = gpu.block_id  z upper_bound 8
        %thread_id_x = gpu.thread_id  x upper_bound 64
        %alloc = memref.alloc() : memref<17408xi8, #gpu.address_space<workgroup>>
        %0 = stream.binding.subspan %arg3[%c0] : !stream.binding -> memref<?xi32, strided<[1], offset: ?>>{%arg9}
        %1 = vector.load %0[%block_id_x] : memref<?xi32, strided<[1], offset: ?>>, vector<1xi32>
        %2 = affine.apply #map()[%block_id_x]
        %3 = vector.load %0[%2] : memref<?xi32, strided<[1], offset: ?>>, vector<1xi32>
        %4 = vector.extract %3[0] : i32 from vector<1xi32>
        %5 = arith.index_cast %4 : i32 to index
        %6 = arith.subi %3, %1 : vector<1xi32>
        %7 = vector.extract %1[0] : i32 from vector<1xi32>
        %8 = arith.index_cast %7 : i32 to index
        %9 = arith.index_cast %6 : vector<1xi32> to vector<1xindex>
        %10 = arith.ceildivsi %9, %cst_2 : vector<1xindex>
        %11 = arith.index_cast %10 : vector<1xindex> to vector<1xi32>
        %12 = vector.splat %block_id_z : vector<1xindex>
        %13 = arith.index_cast %12 : vector<1xindex> to vector<1xi32>
        %14 = arith.muli %13, %11 : vector<1xi32>
        %15 = vector.extract %14[0] : i32 from vector<1xi32>
        %16 = arith.index_cast %15 : i32 to index
        %17 = vector.extract %11[0] : i32 from vector<1xi32>
        %18 = arith.index_cast %17 : i32 to index
        %19 = vector.extract %6[0] : i32 from vector<1xi32>
        %20 = arith.index_cast %19 : i32 to index
        %21 = arith.subi %20, %16 : index
        %22 = arith.maxsi %21, %c0 : index
        %23 = arith.minsi %22, %18 : index
        %view = memref.view %alloc[%c0][] : memref<17408xi8, #gpu.address_space<workgroup>> to memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
        %view_7 = memref.view %alloc[%c8704][] : memref<17408xi8, #gpu.address_space<workgroup>> to memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
        %24 = stream.binding.subspan %arg0[%c0] : !stream.binding -> memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>{%arg9}
        %25 = vector.load %24[%block_id_x, %block_id_y, %c0] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %26 = vector.load %24[%block_id_x, %block_id_y, %c4] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %27 = vector.load %24[%block_id_x, %block_id_y, %c8] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %28 = vector.load %24[%block_id_x, %block_id_y, %c12] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %29 = vector.load %24[%block_id_x, %block_id_y, %c16] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %30 = vector.load %24[%block_id_x, %block_id_y, %c20] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %31 = vector.load %24[%block_id_x, %block_id_y, %c24] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %32 = vector.load %24[%block_id_x, %block_id_y, %c28] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %33 = vector.load %24[%block_id_x, %block_id_y, %c32] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %34 = vector.load %24[%block_id_x, %block_id_y, %c36] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %35 = vector.load %24[%block_id_x, %block_id_y, %c40] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %36 = vector.load %24[%block_id_x, %block_id_y, %c44] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %37 = vector.load %24[%block_id_x, %block_id_y, %c48] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %38 = vector.load %24[%block_id_x, %block_id_y, %c52] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %39 = vector.load %24[%block_id_x, %block_id_y, %c56] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %40 = vector.load %24[%block_id_x, %block_id_y, %c60] : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<4xf16>
        %41 = affine.apply #map1()[%23]
        %42 = stream.binding.subspan %arg2[%c0] : !stream.binding -> memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>{%arg8}
        %43 = stream.binding.subspan %arg1[%c0] : !stream.binding -> memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>{%arg8}
        %44 = stream.binding.subspan %arg4[%c0] : !stream.binding -> memref<?xi32, strided<[1], offset: ?>>{%arg7}
        %45 = affine.apply #map2()[%thread_id_x]
        %46 = affine.apply #map3()[%thread_id_x]
        %47 = affine.apply #map4()[%thread_id_x]
        %48 = affine.apply #map5()[%thread_id_x]
        %49 = affine.apply #map6()[%thread_id_x]
        %50 = affine.apply #map7()[%thread_id_x]
        %51 = affine.apply #map8()[%thread_id_x]
        %52 = affine.apply #map9()[%thread_id_x]
        %53 = affine.apply #map10()[%thread_id_x]
        %54 = affine.apply #map11()[%thread_id_x]
        %55 = arith.extf %25 : vector<4xf16> to vector<4xf32>
        %56 = arith.extf %26 : vector<4xf16> to vector<4xf32>
        %57 = arith.extf %27 : vector<4xf16> to vector<4xf32>
        %58 = arith.extf %28 : vector<4xf16> to vector<4xf32>
        %59 = arith.extf %29 : vector<4xf16> to vector<4xf32>
        %60 = arith.extf %30 : vector<4xf16> to vector<4xf32>
        %61 = arith.extf %31 : vector<4xf16> to vector<4xf32>
        %62 = arith.extf %32 : vector<4xf16> to vector<4xf32>
        %63 = arith.extf %33 : vector<4xf16> to vector<4xf32>
        %64 = arith.extf %34 : vector<4xf16> to vector<4xf32>
        %65 = arith.extf %35 : vector<4xf16> to vector<4xf32>
        %66 = arith.extf %36 : vector<4xf16> to vector<4xf32>
        %67 = arith.extf %37 : vector<4xf16> to vector<4xf32>
        %68 = arith.extf %38 : vector<4xf16> to vector<4xf32>
        %69 = arith.extf %39 : vector<4xf16> to vector<4xf32>
        %70 = arith.extf %40 : vector<4xf16> to vector<4xf32>
        %71 = affine.apply #map12()[%16, %23, %8]
        %72 = vector.splat %71 : vector<1xindex>
        %73:66 = scf.for %arg10 = %c0 to %41 step %c1 iter_args(%arg11 = %cst_5, %arg12 = %cst_4, %arg13 = %cst_4, %arg14 = %cst_4, %arg15 = %cst_4, %arg16 = %cst_4, %arg17 = %cst_4, %arg18 = %cst_4, %arg19 = %cst_4, %arg20 = %cst_4, %arg21 = %cst_4, %arg22 = %cst_4, %arg23 = %cst_4, %arg24 = %cst_4, %arg25 = %cst_4, %arg26 = %cst_4, %arg27 = %cst_4, %arg28 = %cst_4, %arg29 = %cst_4, %arg30 = %cst_4, %arg31 = %cst_4, %arg32 = %cst_4, %arg33 = %cst_4, %arg34 = %cst_4, %arg35 = %cst_4, %arg36 = %cst_4, %arg37 = %cst_4, %arg38 = %cst_4, %arg39 = %cst_4, %arg40 = %cst_4, %arg41 = %cst_4, %arg42 = %cst_4, %arg43 = %cst_4, %arg44 = %cst_4, %arg45 = %cst_4, %arg46 = %cst_4, %arg47 = %cst_4, %arg48 = %cst_4, %arg49 = %cst_4, %arg50 = %cst_4, %arg51 = %cst_4, %arg52 = %cst_4, %arg53 = %cst_4, %arg54 = %cst_4, %arg55 = %cst_4, %arg56 = %cst_4, %arg57 = %cst_4, %arg58 = %cst_4, %arg59 = %cst_4, %arg60 = %cst_4, %arg61 = %cst_4, %arg62 = %cst_4, %arg63 = %cst_4, %arg64 = %cst_4, %arg65 = %cst_4, %arg66 = %cst_4, %arg67 = %cst_4, %arg68 = %cst_4, %arg69 = %cst_4, %arg70 = %cst_4, %arg71 = %cst_4, %arg72 = %cst_4, %arg73 = %cst_4, %arg74 = %cst_4, %arg75 = %cst_4, %arg76 = %cst_4) -> (vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>) {
          %75 = affine.apply #map13()[%thread_id_x, %arg10, %16, %8]
          %76 = arith.cmpi slt, %75, %5 : index
          %77 = vector.splat %76 : vector<1xi1>
          %78 = vector.maskedload %44[%75], %77, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %79 = affine.apply #map14()[%thread_id_x, %arg10, %16, %8]
          %80 = arith.cmpi slt, %79, %5 : index
          %81 = vector.splat %80 : vector<1xi1>
          %82 = vector.maskedload %44[%79], %81, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %83 = affine.apply #map15()[%thread_id_x, %arg10, %16, %8]
          %84 = arith.cmpi slt, %83, %5 : index
          %85 = vector.splat %84 : vector<1xi1>
          %86 = vector.maskedload %44[%83], %85, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %87 = affine.apply #map16()[%thread_id_x, %arg10, %16, %8]
          %88 = arith.cmpi slt, %87, %5 : index
          %89 = vector.splat %88 : vector<1xi1>
          %90 = vector.maskedload %44[%87], %89, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %91 = affine.apply #map17()[%thread_id_x, %arg10, %16, %8]
          %92 = arith.cmpi slt, %91, %5 : index
          %93 = vector.splat %92 : vector<1xi1>
          %94 = vector.maskedload %44[%91], %93, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %95 = affine.apply #map18()[%thread_id_x, %arg10, %16, %8]
          %96 = arith.cmpi slt, %95, %5 : index
          %97 = vector.splat %96 : vector<1xi1>
          %98 = vector.maskedload %44[%95], %97, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %99 = affine.apply #map19()[%thread_id_x, %arg10, %16, %8]
          %100 = arith.cmpi slt, %99, %5 : index
          %101 = vector.splat %100 : vector<1xi1>
          %102 = vector.maskedload %44[%99], %101, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %103 = affine.apply #map20()[%thread_id_x, %arg10, %16, %8]
          %104 = arith.cmpi slt, %103, %5 : index
          %105 = vector.splat %104 : vector<1xi1>
          %106 = vector.maskedload %44[%103], %105, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %107 = affine.apply #map21()[%thread_id_x, %arg10, %16, %8]
          %108 = arith.cmpi slt, %107, %5 : index
          %109 = vector.splat %108 : vector<1xi1>
          %110 = vector.maskedload %44[%107], %109, %cst_1 : memref<?xi32, strided<[1], offset: ?>>, vector<1xi1>, vector<1xi32> into vector<1xi32>
          %111 = vector.extract %82[0] : i32 from vector<1xi32>
          %112 = arith.index_cast %111 : i32 to index
          %113 = vector.splat %80 : vector<8xi1>
          %114 = vector.maskedload %43[%112, %block_id_y, %45], %113, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          amdgpu.lds_barrier
          vector.store %114, %view_7[%c0, %c0, %46, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %115 = vector.extract %110[0] : i32 from vector<1xi32>
          %116 = arith.index_cast %115 : i32 to index
          %117 = vector.splat %108 : vector<8xi1>
          %118 = vector.maskedload %43[%116, %block_id_y, %45], %117, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %118, %view_7[%c0, %c0, %47, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %119 = vector.extract %106[0] : i32 from vector<1xi32>
          %120 = arith.index_cast %119 : i32 to index
          %121 = vector.splat %104 : vector<8xi1>
          %122 = vector.maskedload %43[%120, %block_id_y, %45], %121, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %122, %view_7[%c0, %c0, %48, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %123 = vector.extract %102[0] : i32 from vector<1xi32>
          %124 = arith.index_cast %123 : i32 to index
          %125 = vector.splat %100 : vector<8xi1>
          %126 = vector.maskedload %43[%124, %block_id_y, %45], %125, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %126, %view_7[%c0, %c0, %49, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %127 = vector.extract %98[0] : i32 from vector<1xi32>
          %128 = arith.index_cast %127 : i32 to index
          %129 = vector.splat %96 : vector<8xi1>
          %130 = vector.maskedload %43[%128, %block_id_y, %45], %129, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %130, %view_7[%c0, %c0, %50, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %131 = vector.extract %94[0] : i32 from vector<1xi32>
          %132 = arith.index_cast %131 : i32 to index
          %133 = vector.splat %92 : vector<8xi1>
          %134 = vector.maskedload %43[%132, %block_id_y, %45], %133, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %134, %view_7[%c0, %c0, %51, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %135 = vector.extract %90[0] : i32 from vector<1xi32>
          %136 = arith.index_cast %135 : i32 to index
          %137 = vector.splat %88 : vector<8xi1>
          %138 = vector.maskedload %43[%136, %block_id_y, %45], %137, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %138, %view_7[%c0, %c0, %52, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %139 = vector.extract %86[0] : i32 from vector<1xi32>
          %140 = arith.index_cast %139 : i32 to index
          %141 = vector.splat %84 : vector<8xi1>
          %142 = vector.maskedload %43[%140, %block_id_y, %45], %141, %cst_0 : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<8xi1>, vector<8xf16> into vector<8xf16>
          vector.store %142, %view_7[%c0, %c0, %53, %45] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<8xf16>
          %143 = vector.extract %78[0] : i32 from vector<1xi32>
          %144 = arith.index_cast %143 : i32 to index
          %145 = vector.maskedload %42[%144, %block_id_y, %c0], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %146 = vector.maskedload %42[%144, %block_id_y, %c1], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %147 = vector.maskedload %42[%144, %block_id_y, %c2], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %148 = vector.maskedload %42[%144, %block_id_y, %c3], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %149 = vector.maskedload %42[%144, %block_id_y, %c4], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %150 = vector.maskedload %42[%144, %block_id_y, %c5], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %151 = vector.maskedload %42[%144, %block_id_y, %c6], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %152 = vector.maskedload %42[%144, %block_id_y, %c7], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %153 = vector.maskedload %42[%144, %block_id_y, %c8], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %154 = vector.maskedload %42[%144, %block_id_y, %c9], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %155 = vector.maskedload %42[%144, %block_id_y, %c10], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %156 = vector.maskedload %42[%144, %block_id_y, %c11], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %157 = vector.maskedload %42[%144, %block_id_y, %c12], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %158 = vector.maskedload %42[%144, %block_id_y, %c13], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %159 = vector.maskedload %42[%144, %block_id_y, %c14], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %160 = vector.maskedload %42[%144, %block_id_y, %c15], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %161 = vector.maskedload %42[%144, %block_id_y, %c16], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %162 = vector.maskedload %42[%144, %block_id_y, %c17], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %163 = vector.maskedload %42[%144, %block_id_y, %c18], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %164 = vector.maskedload %42[%144, %block_id_y, %c19], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %165 = vector.maskedload %42[%144, %block_id_y, %c20], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %166 = vector.maskedload %42[%144, %block_id_y, %c21], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %167 = vector.maskedload %42[%144, %block_id_y, %c22], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %168 = vector.maskedload %42[%144, %block_id_y, %c23], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %169 = vector.maskedload %42[%144, %block_id_y, %c24], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %170 = vector.maskedload %42[%144, %block_id_y, %c25], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %171 = vector.maskedload %42[%144, %block_id_y, %c26], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %172 = vector.maskedload %42[%144, %block_id_y, %c27], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %173 = vector.maskedload %42[%144, %block_id_y, %c28], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %174 = vector.maskedload %42[%144, %block_id_y, %c29], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %175 = vector.maskedload %42[%144, %block_id_y, %c30], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %176 = vector.maskedload %42[%144, %block_id_y, %c31], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %177 = vector.maskedload %42[%144, %block_id_y, %c32], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %178 = vector.maskedload %42[%144, %block_id_y, %c33], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %179 = vector.maskedload %42[%144, %block_id_y, %c34], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %180 = vector.maskedload %42[%144, %block_id_y, %c35], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %181 = vector.maskedload %42[%144, %block_id_y, %c36], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %182 = vector.maskedload %42[%144, %block_id_y, %c37], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %183 = vector.maskedload %42[%144, %block_id_y, %c38], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %184 = vector.maskedload %42[%144, %block_id_y, %c39], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %185 = vector.maskedload %42[%144, %block_id_y, %c40], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %186 = vector.maskedload %42[%144, %block_id_y, %c41], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %187 = vector.maskedload %42[%144, %block_id_y, %c42], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %188 = vector.maskedload %42[%144, %block_id_y, %c43], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %189 = vector.maskedload %42[%144, %block_id_y, %c44], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %190 = vector.maskedload %42[%144, %block_id_y, %c45], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %191 = vector.maskedload %42[%144, %block_id_y, %c46], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %192 = vector.maskedload %42[%144, %block_id_y, %c47], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %193 = vector.maskedload %42[%144, %block_id_y, %c48], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %194 = vector.maskedload %42[%144, %block_id_y, %c49], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %195 = vector.maskedload %42[%144, %block_id_y, %c50], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %196 = vector.maskedload %42[%144, %block_id_y, %c51], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %197 = vector.maskedload %42[%144, %block_id_y, %c52], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %198 = vector.maskedload %42[%144, %block_id_y, %c53], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %199 = vector.maskedload %42[%144, %block_id_y, %c54], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %200 = vector.maskedload %42[%144, %block_id_y, %c55], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %201 = vector.maskedload %42[%144, %block_id_y, %c56], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %202 = vector.maskedload %42[%144, %block_id_y, %c57], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %203 = vector.maskedload %42[%144, %block_id_y, %c58], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %204 = vector.maskedload %42[%144, %block_id_y, %c59], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %205 = vector.maskedload %42[%144, %block_id_y, %c60], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %206 = vector.maskedload %42[%144, %block_id_y, %c61], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %207 = vector.maskedload %42[%144, %block_id_y, %c62], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          %208 = vector.maskedload %42[%144, %block_id_y, %c63], %77, %cst : memref<?x16x64xf16, strided<[1024, 64, 1], offset: ?>>, vector<1xi1>, vector<1xf16> into vector<1xf16>
          vector.store %145, %view[%c0, %c0, %c0, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %146, %view[%c0, %c0, %c1, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %147, %view[%c0, %c0, %c2, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %148, %view[%c0, %c0, %c3, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %149, %view[%c0, %c0, %c4, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %150, %view[%c0, %c0, %c5, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %151, %view[%c0, %c0, %c6, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %152, %view[%c0, %c0, %c7, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %153, %view[%c0, %c0, %c8, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %154, %view[%c0, %c0, %c9, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %155, %view[%c0, %c0, %c10, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %156, %view[%c0, %c0, %c11, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %157, %view[%c0, %c0, %c12, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %158, %view[%c0, %c0, %c13, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %159, %view[%c0, %c0, %c14, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %160, %view[%c0, %c0, %c15, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %161, %view[%c0, %c0, %c16, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %162, %view[%c0, %c0, %c17, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %163, %view[%c0, %c0, %c18, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %164, %view[%c0, %c0, %c19, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %165, %view[%c0, %c0, %c20, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %166, %view[%c0, %c0, %c21, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %167, %view[%c0, %c0, %c22, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %168, %view[%c0, %c0, %c23, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %169, %view[%c0, %c0, %c24, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %170, %view[%c0, %c0, %c25, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %171, %view[%c0, %c0, %c26, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %172, %view[%c0, %c0, %c27, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %173, %view[%c0, %c0, %c28, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %174, %view[%c0, %c0, %c29, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %175, %view[%c0, %c0, %c30, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %176, %view[%c0, %c0, %c31, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %177, %view[%c0, %c0, %c32, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %178, %view[%c0, %c0, %c33, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %179, %view[%c0, %c0, %c34, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %180, %view[%c0, %c0, %c35, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %181, %view[%c0, %c0, %c36, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %182, %view[%c0, %c0, %c37, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %183, %view[%c0, %c0, %c38, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %184, %view[%c0, %c0, %c39, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %185, %view[%c0, %c0, %c40, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %186, %view[%c0, %c0, %c41, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %187, %view[%c0, %c0, %c42, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %188, %view[%c0, %c0, %c43, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %189, %view[%c0, %c0, %c44, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %190, %view[%c0, %c0, %c45, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %191, %view[%c0, %c0, %c46, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %192, %view[%c0, %c0, %c47, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %193, %view[%c0, %c0, %c48, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %194, %view[%c0, %c0, %c49, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %195, %view[%c0, %c0, %c50, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %196, %view[%c0, %c0, %c51, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %197, %view[%c0, %c0, %c52, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %198, %view[%c0, %c0, %c53, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %199, %view[%c0, %c0, %c54, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %200, %view[%c0, %c0, %c55, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %201, %view[%c0, %c0, %c56, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %202, %view[%c0, %c0, %c57, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %203, %view[%c0, %c0, %c58, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %204, %view[%c0, %c0, %c59, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %205, %view[%c0, %c0, %c60, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %206, %view[%c0, %c0, %c61, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %207, %view[%c0, %c0, %c62, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          vector.store %208, %view[%c0, %c0, %c63, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<1xf16>
          amdgpu.lds_barrier
          %209 = memref.load %view[%c0, %c0, %c0, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %210 = memref.load %view[%c0, %c0, %c1, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %211 = memref.load %view[%c0, %c0, %c2, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %212 = memref.load %view[%c0, %c0, %c3, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %213 = memref.load %view[%c0, %c0, %c4, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %214 = memref.load %view[%c0, %c0, %c5, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %215 = memref.load %view[%c0, %c0, %c6, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %216 = memref.load %view[%c0, %c0, %c7, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %217 = memref.load %view[%c0, %c0, %c8, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %218 = memref.load %view[%c0, %c0, %c9, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %219 = memref.load %view[%c0, %c0, %c10, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %220 = memref.load %view[%c0, %c0, %c11, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %221 = memref.load %view[%c0, %c0, %c12, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %222 = memref.load %view[%c0, %c0, %c13, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %223 = memref.load %view[%c0, %c0, %c14, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %224 = memref.load %view[%c0, %c0, %c15, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %225 = memref.load %view[%c0, %c0, %c16, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %226 = memref.load %view[%c0, %c0, %c17, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %227 = memref.load %view[%c0, %c0, %c18, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %228 = memref.load %view[%c0, %c0, %c19, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %229 = memref.load %view[%c0, %c0, %c20, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %230 = memref.load %view[%c0, %c0, %c21, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %231 = memref.load %view[%c0, %c0, %c22, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %232 = memref.load %view[%c0, %c0, %c23, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %233 = memref.load %view[%c0, %c0, %c24, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %234 = memref.load %view[%c0, %c0, %c25, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %235 = memref.load %view[%c0, %c0, %c26, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %236 = memref.load %view[%c0, %c0, %c27, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %237 = memref.load %view[%c0, %c0, %c28, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %238 = memref.load %view[%c0, %c0, %c29, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %239 = memref.load %view[%c0, %c0, %c30, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %240 = memref.load %view[%c0, %c0, %c31, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %241 = memref.load %view[%c0, %c0, %c32, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %242 = memref.load %view[%c0, %c0, %c33, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %243 = memref.load %view[%c0, %c0, %c34, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %244 = memref.load %view[%c0, %c0, %c35, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %245 = memref.load %view[%c0, %c0, %c36, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %246 = memref.load %view[%c0, %c0, %c37, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %247 = memref.load %view[%c0, %c0, %c38, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %248 = memref.load %view[%c0, %c0, %c39, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %249 = memref.load %view[%c0, %c0, %c40, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %250 = memref.load %view[%c0, %c0, %c41, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %251 = memref.load %view[%c0, %c0, %c42, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %252 = memref.load %view[%c0, %c0, %c43, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %253 = memref.load %view[%c0, %c0, %c44, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %254 = memref.load %view[%c0, %c0, %c45, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %255 = memref.load %view[%c0, %c0, %c46, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %256 = memref.load %view[%c0, %c0, %c47, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %257 = memref.load %view[%c0, %c0, %c48, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %258 = memref.load %view[%c0, %c0, %c49, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %259 = memref.load %view[%c0, %c0, %c50, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %260 = memref.load %view[%c0, %c0, %c51, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %261 = memref.load %view[%c0, %c0, %c52, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %262 = memref.load %view[%c0, %c0, %c53, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %263 = memref.load %view[%c0, %c0, %c54, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %264 = memref.load %view[%c0, %c0, %c55, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %265 = memref.load %view[%c0, %c0, %c56, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %266 = memref.load %view[%c0, %c0, %c57, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %267 = memref.load %view[%c0, %c0, %c58, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %268 = memref.load %view[%c0, %c0, %c59, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %269 = memref.load %view[%c0, %c0, %c60, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %270 = memref.load %view[%c0, %c0, %c61, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %271 = memref.load %view[%c0, %c0, %c62, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %272 = memref.load %view[%c0, %c0, %c63, %54] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>
          %273 = vector.load %view_7[%c0, %c0, %54, %c0] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %274 = vector.load %view_7[%c0, %c0, %54, %c4] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %275 = vector.load %view_7[%c0, %c0, %54, %c8] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %276 = vector.load %view_7[%c0, %c0, %54, %c12] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %277 = vector.load %view_7[%c0, %c0, %54, %c16] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %278 = vector.load %view_7[%c0, %c0, %54, %c20] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %279 = vector.load %view_7[%c0, %c0, %54, %c24] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %280 = vector.load %view_7[%c0, %c0, %54, %c28] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %281 = vector.load %view_7[%c0, %c0, %54, %c32] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %282 = vector.load %view_7[%c0, %c0, %54, %c36] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %283 = vector.load %view_7[%c0, %c0, %54, %c40] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %284 = vector.load %view_7[%c0, %c0, %54, %c44] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %285 = vector.load %view_7[%c0, %c0, %54, %c48] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %286 = vector.load %view_7[%c0, %c0, %54, %c52] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %287 = vector.load %view_7[%c0, %c0, %54, %c56] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %288 = vector.load %view_7[%c0, %c0, %54, %c60] : memref<1x1x64x68xf16, #gpu.address_space<workgroup>>, vector<4xf16>
          %289 = arith.extf %273 : vector<4xf16> to vector<4xf32>
          %290 = arith.mulf %289, %55 : vector<4xf32>
          %291 = vector.extract %290[0] : f32 from vector<4xf32>
          %292 = vector.extract %290[1] : f32 from vector<4xf32>
          %293 = arith.addf %291, %292 : f32
          %294 = vector.extract %290[2] : f32 from vector<4xf32>
          %295 = arith.addf %293, %294 : f32
          %296 = vector.extract %290[3] : f32 from vector<4xf32>
          %297 = arith.addf %295, %296 : f32
          %298 = vector.broadcast %297 : f32 to vector<1xf32>
          %299 = arith.addf %298, %cst_4 : vector<1xf32>
          %300 = arith.extf %274 : vector<4xf16> to vector<4xf32>
          %301 = arith.mulf %300, %56 : vector<4xf32>
          %302 = vector.extract %301[0] : f32 from vector<4xf32>
          %303 = vector.extract %301[1] : f32 from vector<4xf32>
          %304 = arith.addf %302, %303 : f32
          %305 = vector.extract %301[2] : f32 from vector<4xf32>
          %306 = arith.addf %304, %305 : f32
          %307 = vector.extract %301[3] : f32 from vector<4xf32>
          %308 = arith.addf %306, %307 : f32
          %309 = vector.broadcast %308 : f32 to vector<1xf32>
          %310 = arith.addf %309, %299 : vector<1xf32>
          %311 = arith.extf %275 : vector<4xf16> to vector<4xf32>
          %312 = arith.mulf %311, %57 : vector<4xf32>
          %313 = vector.extract %312[0] : f32 from vector<4xf32>
          %314 = vector.extract %312[1] : f32 from vector<4xf32>
          %315 = arith.addf %313, %314 : f32
          %316 = vector.extract %312[2] : f32 from vector<4xf32>
          %317 = arith.addf %315, %316 : f32
          %318 = vector.extract %312[3] : f32 from vector<4xf32>
          %319 = arith.addf %317, %318 : f32
          %320 = vector.broadcast %319 : f32 to vector<1xf32>
          %321 = arith.addf %320, %310 : vector<1xf32>
          %322 = arith.extf %276 : vector<4xf16> to vector<4xf32>
          %323 = arith.mulf %322, %58 : vector<4xf32>
          %324 = vector.extract %323[0] : f32 from vector<4xf32>
          %325 = vector.extract %323[1] : f32 from vector<4xf32>
          %326 = arith.addf %324, %325 : f32
          %327 = vector.extract %323[2] : f32 from vector<4xf32>
          %328 = arith.addf %326, %327 : f32
          %329 = vector.extract %323[3] : f32 from vector<4xf32>
          %330 = arith.addf %328, %329 : f32
          %331 = vector.broadcast %330 : f32 to vector<1xf32>
          %332 = arith.addf %331, %321 : vector<1xf32>
          %333 = arith.extf %277 : vector<4xf16> to vector<4xf32>
          %334 = arith.mulf %333, %59 : vector<4xf32>
          %335 = vector.extract %334[0] : f32 from vector<4xf32>
          %336 = vector.extract %334[1] : f32 from vector<4xf32>
          %337 = arith.addf %335, %336 : f32
          %338 = vector.extract %334[2] : f32 from vector<4xf32>
          %339 = arith.addf %337, %338 : f32
          %340 = vector.extract %334[3] : f32 from vector<4xf32>
          %341 = arith.addf %339, %340 : f32
          %342 = vector.broadcast %341 : f32 to vector<1xf32>
          %343 = arith.addf %342, %332 : vector<1xf32>
          %344 = arith.extf %278 : vector<4xf16> to vector<4xf32>
          %345 = arith.mulf %344, %60 : vector<4xf32>
          %346 = vector.extract %345[0] : f32 from vector<4xf32>
          %347 = vector.extract %345[1] : f32 from vector<4xf32>
          %348 = arith.addf %346, %347 : f32
          %349 = vector.extract %345[2] : f32 from vector<4xf32>
          %350 = arith.addf %348, %349 : f32
          %351 = vector.extract %345[3] : f32 from vector<4xf32>
          %352 = arith.addf %350, %351 : f32
          %353 = vector.broadcast %352 : f32 to vector<1xf32>
          %354 = arith.addf %353, %343 : vector<1xf32>
          %355 = arith.extf %279 : vector<4xf16> to vector<4xf32>
          %356 = arith.mulf %355, %61 : vector<4xf32>
          %357 = vector.extract %356[0] : f32 from vector<4xf32>
          %358 = vector.extract %356[1] : f32 from vector<4xf32>
          %359 = arith.addf %357, %358 : f32
          %360 = vector.extract %356[2] : f32 from vector<4xf32>
          %361 = arith.addf %359, %360 : f32
          %362 = vector.extract %356[3] : f32 from vector<4xf32>
          %363 = arith.addf %361, %362 : f32
          %364 = vector.broadcast %363 : f32 to vector<1xf32>
          %365 = arith.addf %364, %354 : vector<1xf32>
          %366 = arith.extf %280 : vector<4xf16> to vector<4xf32>
          %367 = arith.mulf %366, %62 : vector<4xf32>
          %368 = vector.extract %367[0] : f32 from vector<4xf32>
          %369 = vector.extract %367[1] : f32 from vector<4xf32>
          %370 = arith.addf %368, %369 : f32
          %371 = vector.extract %367[2] : f32 from vector<4xf32>
          %372 = arith.addf %370, %371 : f32
          %373 = vector.extract %367[3] : f32 from vector<4xf32>
          %374 = arith.addf %372, %373 : f32
          %375 = vector.broadcast %374 : f32 to vector<1xf32>
          %376 = arith.addf %375, %365 : vector<1xf32>
          %377 = arith.extf %281 : vector<4xf16> to vector<4xf32>
          %378 = arith.mulf %377, %63 : vector<4xf32>
          %379 = vector.extract %378[0] : f32 from vector<4xf32>
          %380 = vector.extract %378[1] : f32 from vector<4xf32>
          %381 = arith.addf %379, %380 : f32
          %382 = vector.extract %378[2] : f32 from vector<4xf32>
          %383 = arith.addf %381, %382 : f32
          %384 = vector.extract %378[3] : f32 from vector<4xf32>
          %385 = arith.addf %383, %384 : f32
          %386 = vector.broadcast %385 : f32 to vector<1xf32>
          %387 = arith.addf %386, %376 : vector<1xf32>
          %388 = arith.extf %282 : vector<4xf16> to vector<4xf32>
          %389 = arith.mulf %388, %64 : vector<4xf32>
          %390 = vector.extract %389[0] : f32 from vector<4xf32>
          %391 = vector.extract %389[1] : f32 from vector<4xf32>
          %392 = arith.addf %390, %391 : f32
          %393 = vector.extract %389[2] : f32 from vector<4xf32>
          %394 = arith.addf %392, %393 : f32
          %395 = vector.extract %389[3] : f32 from vector<4xf32>
          %396 = arith.addf %394, %395 : f32
          %397 = vector.broadcast %396 : f32 to vector<1xf32>
          %398 = arith.addf %397, %387 : vector<1xf32>
          %399 = arith.extf %283 : vector<4xf16> to vector<4xf32>
          %400 = arith.mulf %399, %65 : vector<4xf32>
          %401 = vector.extract %400[0] : f32 from vector<4xf32>
          %402 = vector.extract %400[1] : f32 from vector<4xf32>
          %403 = arith.addf %401, %402 : f32
          %404 = vector.extract %400[2] : f32 from vector<4xf32>
          %405 = arith.addf %403, %404 : f32
          %406 = vector.extract %400[3] : f32 from vector<4xf32>
          %407 = arith.addf %405, %406 : f32
          %408 = vector.broadcast %407 : f32 to vector<1xf32>
          %409 = arith.addf %408, %398 : vector<1xf32>
          %410 = arith.extf %284 : vector<4xf16> to vector<4xf32>
          %411 = arith.mulf %410, %66 : vector<4xf32>
          %412 = vector.extract %411[0] : f32 from vector<4xf32>
          %413 = vector.extract %411[1] : f32 from vector<4xf32>
          %414 = arith.addf %412, %413 : f32
          %415 = vector.extract %411[2] : f32 from vector<4xf32>
          %416 = arith.addf %414, %415 : f32
          %417 = vector.extract %411[3] : f32 from vector<4xf32>
          %418 = arith.addf %416, %417 : f32
          %419 = vector.broadcast %418 : f32 to vector<1xf32>
          %420 = arith.addf %419, %409 : vector<1xf32>
          %421 = arith.extf %285 : vector<4xf16> to vector<4xf32>
          %422 = arith.mulf %421, %67 : vector<4xf32>
          %423 = vector.extract %422[0] : f32 from vector<4xf32>
          %424 = vector.extract %422[1] : f32 from vector<4xf32>
          %425 = arith.addf %423, %424 : f32
          %426 = vector.extract %422[2] : f32 from vector<4xf32>
          %427 = arith.addf %425, %426 : f32
          %428 = vector.extract %422[3] : f32 from vector<4xf32>
          %429 = arith.addf %427, %428 : f32
          %430 = vector.broadcast %429 : f32 to vector<1xf32>
          %431 = arith.addf %430, %420 : vector<1xf32>
          %432 = arith.extf %286 : vector<4xf16> to vector<4xf32>
          %433 = arith.mulf %432, %68 : vector<4xf32>
          %434 = vector.extract %433[0] : f32 from vector<4xf32>
          %435 = vector.extract %433[1] : f32 from vector<4xf32>
          %436 = arith.addf %434, %435 : f32
          %437 = vector.extract %433[2] : f32 from vector<4xf32>
          %438 = arith.addf %436, %437 : f32
          %439 = vector.extract %433[3] : f32 from vector<4xf32>
          %440 = arith.addf %438, %439 : f32
          %441 = vector.broadcast %440 : f32 to vector<1xf32>
          %442 = arith.addf %441, %431 : vector<1xf32>
          %443 = arith.extf %287 : vector<4xf16> to vector<4xf32>
          %444 = arith.mulf %443, %69 : vector<4xf32>
          %445 = vector.extract %444[0] : f32 from vector<4xf32>
          %446 = vector.extract %444[1] : f32 from vector<4xf32>
          %447 = arith.addf %445, %446 : f32
          %448 = vector.extract %444[2] : f32 from vector<4xf32>
          %449 = arith.addf %447, %448 : f32
          %450 = vector.extract %444[3] : f32 from vector<4xf32>
          %451 = arith.addf %449, %450 : f32
          %452 = vector.broadcast %451 : f32 to vector<1xf32>
          %453 = arith.addf %452, %442 : vector<1xf32>
          %454 = arith.extf %288 : vector<4xf16> to vector<4xf32>
          %455 = arith.mulf %454, %70 : vector<4xf32>
          %456 = vector.extract %455[0] : f32 from vector<4xf32>
          %457 = vector.extract %455[1] : f32 from vector<4xf32>
          %458 = arith.addf %456, %457 : f32
          %459 = vector.extract %455[2] : f32 from vector<4xf32>
          %460 = arith.addf %458, %459 : f32
          %461 = vector.extract %455[3] : f32 from vector<4xf32>
          %462 = arith.addf %460, %461 : f32
          %463 = vector.broadcast %462 : f32 to vector<1xf32>
          %464 = arith.addf %463, %453 : vector<1xf32>
          %465 = arith.mulf %464, %cst_6 : vector<1xf32>
          %466 = vector.splat %75 : vector<1xindex>
          %467 = arith.cmpi slt, %466, %72 : vector<1xindex>
          %468 = arith.select %467, %cst_4, %cst_5 : vector<1xi1>, vector<1xf32>
          %469 = arith.addf %465, %468 : vector<1xf32>
          %470 = vector.extract %469[0] : f32 from vector<1xf32>
          %471 = vector.splat %470 : vector<1xf32>
          %shuffleResult, %valid = gpu.shuffle  xor %471, %c1_i32, %c64_i32 : vector<1xf32>
          %472 = arith.maximumf %471, %shuffleResult : vector<1xf32>
          %shuffleResult_8, %valid_9 = gpu.shuffle  xor %472, %c2_i32, %c64_i32 : vector<1xf32>
          %473 = arith.maximumf %472, %shuffleResult_8 : vector<1xf32>
          %shuffleResult_10, %valid_11 = gpu.shuffle  xor %473, %c4_i32, %c64_i32 : vector<1xf32>
          %474 = arith.maximumf %473, %shuffleResult_10 : vector<1xf32>
          %shuffleResult_12, %valid_13 = gpu.shuffle  xor %474, %c8_i32, %c64_i32 : vector<1xf32>
          %475 = arith.maximumf %474, %shuffleResult_12 : vector<1xf32>
          %shuffleResult_14, %valid_15 = gpu.shuffle  xor %475, %c16_i32, %c64_i32 : vector<1xf32>
          %476 = arith.maximumf %475, %shuffleResult_14 : vector<1xf32>
          %shuffleResult_16, %valid_17 = gpu.shuffle  xor %476, %c32_i32, %c64_i32 : vector<1xf32>
          %477 = arith.maximumf %476, %shuffleResult_16 : vector<1xf32>
          %478 = arith.maximumf %arg11, %477 : vector<1xf32>
          %479 = arith.subf %arg11, %478 : vector<1xf32>
          %480 = math.exp2 %479 : vector<1xf32>
          %481 = arith.subf %469, %478 : vector<1xf32>
          %482 = math.exp2 %481 : vector<1xf32>
          %483 = arith.mulf %arg12, %480 : vector<1xf32>
          %484 = vector.extract %482[0] : f32 from vector<1xf32>
          %485 = vector.splat %484 : vector<1xf32>
          %shuffleResult_18, %valid_19 = gpu.shuffle  xor %485, %c1_i32, %c64_i32 : vector<1xf32>
          %486 = arith.addf %485, %shuffleResult_18 : vector<1xf32>
          %shuffleResult_20, %valid_21 = gpu.shuffle  xor %486, %c2_i32, %c64_i32 : vector<1xf32>
          %487 = arith.addf %486, %shuffleResult_20 : vector<1xf32>
          %shuffleResult_22, %valid_23 = gpu.shuffle  xor %487, %c4_i32, %c64_i32 : vector<1xf32>
          %488 = arith.addf %487, %shuffleResult_22 : vector<1xf32>
          %shuffleResult_24, %valid_25 = gpu.shuffle  xor %488, %c8_i32, %c64_i32 : vector<1xf32>
          %489 = arith.addf %488, %shuffleResult_24 : vector<1xf32>
          %shuffleResult_26, %valid_27 = gpu.shuffle  xor %489, %c16_i32, %c64_i32 : vector<1xf32>
          %490 = arith.addf %489, %shuffleResult_26 : vector<1xf32>
          %shuffleResult_28, %valid_29 = gpu.shuffle  xor %490, %c32_i32, %c64_i32 : vector<1xf32>
          %491 = arith.addf %490, %shuffleResult_28 : vector<1xf32>
          %492 = arith.addf %483, %491 : vector<1xf32>
          %493 = arith.truncf %482 : vector<1xf32> to vector<1xf16>
          %494 = arith.mulf %arg13, %480 : vector<1xf32>
          %495 = arith.mulf %arg14, %480 : vector<1xf32>
          %496 = arith.mulf %arg15, %480 : vector<1xf32>
          %497 = arith.mulf %arg16, %480 : vector<1xf32>
          %498 = arith.mulf %arg17, %480 : vector<1xf32>
          %499 = arith.mulf %arg18, %480 : vector<1xf32>
          %500 = arith.mulf %arg19, %480 : vector<1xf32>
          %501 = arith.mulf %arg20, %480 : vector<1xf32>
          %502 = arith.mulf %arg21, %480 : vector<1xf32>
          %503 = arith.mulf %arg22, %480 : vector<1xf32>
          %504 = arith.mulf %arg23, %480 : vector<1xf32>
          %505 = arith.mulf %arg24, %480 : vector<1xf32>
          %506 = arith.mulf %arg25, %480 : vector<1xf32>
          %507 = arith.mulf %arg26, %480 : vector<1xf32>
          %508 = arith.mulf %arg27, %480 : vector<1xf32>
          %509 = arith.mulf %arg28, %480 : vector<1xf32>
          %510 = arith.mulf %arg29, %480 : vector<1xf32>
          %511 = arith.mulf %arg30, %480 : vector<1xf32>
          %512 = arith.mulf %arg31, %480 : vector<1xf32>
          %513 = arith.mulf %arg32, %480 : vector<1xf32>
          %514 = arith.mulf %arg33, %480 : vector<1xf32>
          %515 = arith.mulf %arg34, %480 : vector<1xf32>
          %516 = arith.mulf %arg35, %480 : vector<1xf32>
          %517 = arith.mulf %arg36, %480 : vector<1xf32>
          %518 = arith.mulf %arg37, %480 : vector<1xf32>
          %519 = arith.mulf %arg38, %480 : vector<1xf32>
          %520 = arith.mulf %arg39, %480 : vector<1xf32>
          %521 = arith.mulf %arg40, %480 : vector<1xf32>
          %522 = arith.mulf %arg41, %480 : vector<1xf32>
          %523 = arith.mulf %arg42, %480 : vector<1xf32>
          %524 = arith.mulf %arg43, %480 : vector<1xf32>
          %525 = arith.mulf %arg44, %480 : vector<1xf32>
          %526 = arith.mulf %arg45, %480 : vector<1xf32>
          %527 = arith.mulf %arg46, %480 : vector<1xf32>
          %528 = arith.mulf %arg47, %480 : vector<1xf32>
          %529 = arith.mulf %arg48, %480 : vector<1xf32>
          %530 = arith.mulf %arg49, %480 : vector<1xf32>
          %531 = arith.mulf %arg50, %480 : vector<1xf32>
          %532 = arith.mulf %arg51, %480 : vector<1xf32>
          %533 = arith.mulf %arg52, %480 : vector<1xf32>
          %534 = arith.mulf %arg53, %480 : vector<1xf32>
          %535 = arith.mulf %arg54, %480 : vector<1xf32>
          %536 = arith.mulf %arg55, %480 : vector<1xf32>
          %537 = arith.mulf %arg56, %480 : vector<1xf32>
          %538 = arith.mulf %arg57, %480 : vector<1xf32>
          %539 = arith.mulf %arg58, %480 : vector<1xf32>
          %540 = arith.mulf %arg59, %480 : vector<1xf32>
          %541 = arith.mulf %arg60, %480 : vector<1xf32>
          %542 = arith.mulf %arg61, %480 : vector<1xf32>
          %543 = arith.mulf %arg62, %480 : vector<1xf32>
          %544 = arith.mulf %arg63, %480 : vector<1xf32>
          %545 = arith.mulf %arg64, %480 : vector<1xf32>
          %546 = arith.mulf %arg65, %480 : vector<1xf32>
          %547 = arith.mulf %arg66, %480 : vector<1xf32>
          %548 = arith.mulf %arg67, %480 : vector<1xf32>
          %549 = arith.mulf %arg68, %480 : vector<1xf32>
          %550 = arith.mulf %arg69, %480 : vector<1xf32>
          %551 = arith.mulf %arg70, %480 : vector<1xf32>
          %552 = arith.mulf %arg71, %480 : vector<1xf32>
          %553 = arith.mulf %arg72, %480 : vector<1xf32>
          %554 = arith.mulf %arg73, %480 : vector<1xf32>
          %555 = arith.mulf %arg74, %480 : vector<1xf32>
          %556 = arith.mulf %arg75, %480 : vector<1xf32>
          %557 = arith.mulf %arg76, %480 : vector<1xf32>
          %558 = arith.extf %209 : f16 to f32
          %559 = vector.extract %493[0] : f16 from vector<1xf16>
          %560 = arith.extf %559 : f16 to f32
          %561 = arith.mulf %558, %560 : f32
          %562 = vector.splat %561 : vector<1xf32>
          %shuffleResult_30, %valid_31 = gpu.shuffle  xor %562, %c1_i32, %c64_i32 : vector<1xf32>
          %563 = arith.addf %562, %shuffleResult_30 : vector<1xf32>
          %shuffleResult_32, %valid_33 = gpu.shuffle  xor %563, %c2_i32, %c64_i32 : vector<1xf32>
          %564 = arith.addf %563, %shuffleResult_32 : vector<1xf32>
          %shuffleResult_34, %valid_35 = gpu.shuffle  xor %564, %c4_i32, %c64_i32 : vector<1xf32>
          %565 = arith.addf %564, %shuffleResult_34 : vector<1xf32>
          %shuffleResult_36, %valid_37 = gpu.shuffle  xor %565, %c8_i32, %c64_i32 : vector<1xf32>
          %566 = arith.addf %565, %shuffleResult_36 : vector<1xf32>
          %shuffleResult_38, %valid_39 = gpu.shuffle  xor %566, %c16_i32, %c64_i32 : vector<1xf32>
          %567 = arith.addf %566, %shuffleResult_38 : vector<1xf32>
          %shuffleResult_40, %valid_41 = gpu.shuffle  xor %567, %c32_i32, %c64_i32 : vector<1xf32>
          %568 = arith.addf %567, %shuffleResult_40 : vector<1xf32>
          %569 = arith.addf %568, %494 : vector<1xf32>
          %570 = arith.extf %210 : f16 to f32
          %571 = arith.mulf %570, %560 : f32
          %572 = vector.splat %571 : vector<1xf32>
          %shuffleResult_42, %valid_43 = gpu.shuffle  xor %572, %c1_i32, %c64_i32 : vector<1xf32>
          %573 = arith.addf %572, %shuffleResult_42 : vector<1xf32>
          %shuffleResult_44, %valid_45 = gpu.shuffle  xor %573, %c2_i32, %c64_i32 : vector<1xf32>
          %574 = arith.addf %573, %shuffleResult_44 : vector<1xf32>
          %shuffleResult_46, %valid_47 = gpu.shuffle  xor %574, %c4_i32, %c64_i32 : vector<1xf32>
          %575 = arith.addf %574, %shuffleResult_46 : vector<1xf32>
          %shuffleResult_48, %valid_49 = gpu.shuffle  xor %575, %c8_i32, %c64_i32 : vector<1xf32>
          %576 = arith.addf %575, %shuffleResult_48 : vector<1xf32>
          %shuffleResult_50, %valid_51 = gpu.shuffle  xor %576, %c16_i32, %c64_i32 : vector<1xf32>
          %577 = arith.addf %576, %shuffleResult_50 : vector<1xf32>
          %shuffleResult_52, %valid_53 = gpu.shuffle  xor %577, %c32_i32, %c64_i32 : vector<1xf32>
          %578 = arith.addf %577, %shuffleResult_52 : vector<1xf32>
          %579 = arith.addf %578, %495 : vector<1xf32>
          %580 = arith.extf %211 : f16 to f32
          %581 = arith.mulf %580, %560 : f32
          %582 = vector.splat %581 : vector<1xf32>
          %shuffleResult_54, %valid_55 = gpu.shuffle  xor %582, %c1_i32, %c64_i32 : vector<1xf32>
          %583 = arith.addf %582, %shuffleResult_54 : vector<1xf32>
          %shuffleResult_56, %valid_57 = gpu.shuffle  xor %583, %c2_i32, %c64_i32 : vector<1xf32>
          %584 = arith.addf %583, %shuffleResult_56 : vector<1xf32>
          %shuffleResult_58, %valid_59 = gpu.shuffle  xor %584, %c4_i32, %c64_i32 : vector<1xf32>
          %585 = arith.addf %584, %shuffleResult_58 : vector<1xf32>
          %shuffleResult_60, %valid_61 = gpu.shuffle  xor %585, %c8_i32, %c64_i32 : vector<1xf32>
          %586 = arith.addf %585, %shuffleResult_60 : vector<1xf32>
          %shuffleResult_62, %valid_63 = gpu.shuffle  xor %586, %c16_i32, %c64_i32 : vector<1xf32>
          %587 = arith.addf %586, %shuffleResult_62 : vector<1xf32>
          %shuffleResult_64, %valid_65 = gpu.shuffle  xor %587, %c32_i32, %c64_i32 : vector<1xf32>
          %588 = arith.addf %587, %shuffleResult_64 : vector<1xf32>
          %589 = arith.addf %588, %496 : vector<1xf32>
          %590 = arith.extf %212 : f16 to f32
          %591 = arith.mulf %590, %560 : f32
          %592 = vector.splat %591 : vector<1xf32>
          %shuffleResult_66, %valid_67 = gpu.shuffle  xor %592, %c1_i32, %c64_i32 : vector<1xf32>
          %593 = arith.addf %592, %shuffleResult_66 : vector<1xf32>
          %shuffleResult_68, %valid_69 = gpu.shuffle  xor %593, %c2_i32, %c64_i32 : vector<1xf32>
          %594 = arith.addf %593, %shuffleResult_68 : vector<1xf32>
          %shuffleResult_70, %valid_71 = gpu.shuffle  xor %594, %c4_i32, %c64_i32 : vector<1xf32>
          %595 = arith.addf %594, %shuffleResult_70 : vector<1xf32>
          %shuffleResult_72, %valid_73 = gpu.shuffle  xor %595, %c8_i32, %c64_i32 : vector<1xf32>
          %596 = arith.addf %595, %shuffleResult_72 : vector<1xf32>
          %shuffleResult_74, %valid_75 = gpu.shuffle  xor %596, %c16_i32, %c64_i32 : vector<1xf32>
          %597 = arith.addf %596, %shuffleResult_74 : vector<1xf32>
          %shuffleResult_76, %valid_77 = gpu.shuffle  xor %597, %c32_i32, %c64_i32 : vector<1xf32>
          %598 = arith.addf %597, %shuffleResult_76 : vector<1xf32>
          %599 = arith.addf %598, %497 : vector<1xf32>
          %600 = arith.extf %213 : f16 to f32
          %601 = arith.mulf %600, %560 : f32
          %602 = vector.splat %601 : vector<1xf32>
          %shuffleResult_78, %valid_79 = gpu.shuffle  xor %602, %c1_i32, %c64_i32 : vector<1xf32>
          %603 = arith.addf %602, %shuffleResult_78 : vector<1xf32>
          %shuffleResult_80, %valid_81 = gpu.shuffle  xor %603, %c2_i32, %c64_i32 : vector<1xf32>
          %604 = arith.addf %603, %shuffleResult_80 : vector<1xf32>
          %shuffleResult_82, %valid_83 = gpu.shuffle  xor %604, %c4_i32, %c64_i32 : vector<1xf32>
          %605 = arith.addf %604, %shuffleResult_82 : vector<1xf32>
          %shuffleResult_84, %valid_85 = gpu.shuffle  xor %605, %c8_i32, %c64_i32 : vector<1xf32>
          %606 = arith.addf %605, %shuffleResult_84 : vector<1xf32>
          %shuffleResult_86, %valid_87 = gpu.shuffle  xor %606, %c16_i32, %c64_i32 : vector<1xf32>
          %607 = arith.addf %606, %shuffleResult_86 : vector<1xf32>
          %shuffleResult_88, %valid_89 = gpu.shuffle  xor %607, %c32_i32, %c64_i32 : vector<1xf32>
          %608 = arith.addf %607, %shuffleResult_88 : vector<1xf32>
          %609 = arith.addf %608, %498 : vector<1xf32>
          %610 = arith.extf %214 : f16 to f32
          %611 = arith.mulf %610, %560 : f32
          %612 = vector.splat %611 : vector<1xf32>
          %shuffleResult_90, %valid_91 = gpu.shuffle  xor %612, %c1_i32, %c64_i32 : vector<1xf32>
          %613 = arith.addf %612, %shuffleResult_90 : vector<1xf32>
          %shuffleResult_92, %valid_93 = gpu.shuffle  xor %613, %c2_i32, %c64_i32 : vector<1xf32>
          %614 = arith.addf %613, %shuffleResult_92 : vector<1xf32>
          %shuffleResult_94, %valid_95 = gpu.shuffle  xor %614, %c4_i32, %c64_i32 : vector<1xf32>
          %615 = arith.addf %614, %shuffleResult_94 : vector<1xf32>
          %shuffleResult_96, %valid_97 = gpu.shuffle  xor %615, %c8_i32, %c64_i32 : vector<1xf32>
          %616 = arith.addf %615, %shuffleResult_96 : vector<1xf32>
          %shuffleResult_98, %valid_99 = gpu.shuffle  xor %616, %c16_i32, %c64_i32 : vector<1xf32>
          %617 = arith.addf %616, %shuffleResult_98 : vector<1xf32>
          %shuffleResult_100, %valid_101 = gpu.shuffle  xor %617, %c32_i32, %c64_i32 : vector<1xf32>
          %618 = arith.addf %617, %shuffleResult_100 : vector<1xf32>
          %619 = arith.addf %618, %499 : vector<1xf32>
          %620 = arith.extf %215 : f16 to f32
          %621 = arith.mulf %620, %560 : f32
          %622 = vector.splat %621 : vector<1xf32>
          %shuffleResult_102, %valid_103 = gpu.shuffle  xor %622, %c1_i32, %c64_i32 : vector<1xf32>
          %623 = arith.addf %622, %shuffleResult_102 : vector<1xf32>
          %shuffleResult_104, %valid_105 = gpu.shuffle  xor %623, %c2_i32, %c64_i32 : vector<1xf32>
          %624 = arith.addf %623, %shuffleResult_104 : vector<1xf32>
          %shuffleResult_106, %valid_107 = gpu.shuffle  xor %624, %c4_i32, %c64_i32 : vector<1xf32>
          %625 = arith.addf %624, %shuffleResult_106 : vector<1xf32>
          %shuffleResult_108, %valid_109 = gpu.shuffle  xor %625, %c8_i32, %c64_i32 : vector<1xf32>
          %626 = arith.addf %625, %shuffleResult_108 : vector<1xf32>
          %shuffleResult_110, %valid_111 = gpu.shuffle  xor %626, %c16_i32, %c64_i32 : vector<1xf32>
          %627 = arith.addf %626, %shuffleResult_110 : vector<1xf32>
          %shuffleResult_112, %valid_113 = gpu.shuffle  xor %627, %c32_i32, %c64_i32 : vector<1xf32>
          %628 = arith.addf %627, %shuffleResult_112 : vector<1xf32>
          %629 = arith.addf %628, %500 : vector<1xf32>
          %630 = arith.extf %216 : f16 to f32
          %631 = arith.mulf %630, %560 : f32
          %632 = vector.splat %631 : vector<1xf32>
          %shuffleResult_114, %valid_115 = gpu.shuffle  xor %632, %c1_i32, %c64_i32 : vector<1xf32>
          %633 = arith.addf %632, %shuffleResult_114 : vector<1xf32>
          %shuffleResult_116, %valid_117 = gpu.shuffle  xor %633, %c2_i32, %c64_i32 : vector<1xf32>
          %634 = arith.addf %633, %shuffleResult_116 : vector<1xf32>
          %shuffleResult_118, %valid_119 = gpu.shuffle  xor %634, %c4_i32, %c64_i32 : vector<1xf32>
          %635 = arith.addf %634, %shuffleResult_118 : vector<1xf32>
          %shuffleResult_120, %valid_121 = gpu.shuffle  xor %635, %c8_i32, %c64_i32 : vector<1xf32>
          %636 = arith.addf %635, %shuffleResult_120 : vector<1xf32>
          %shuffleResult_122, %valid_123 = gpu.shuffle  xor %636, %c16_i32, %c64_i32 : vector<1xf32>
          %637 = arith.addf %636, %shuffleResult_122 : vector<1xf32>
          %shuffleResult_124, %valid_125 = gpu.shuffle  xor %637, %c32_i32, %c64_i32 : vector<1xf32>
          %638 = arith.addf %637, %shuffleResult_124 : vector<1xf32>
          %639 = arith.addf %638, %501 : vector<1xf32>
          %640 = arith.extf %217 : f16 to f32
          %641 = arith.mulf %640, %560 : f32
          %642 = vector.splat %641 : vector<1xf32>
          %shuffleResult_126, %valid_127 = gpu.shuffle  xor %642, %c1_i32, %c64_i32 : vector<1xf32>
          %643 = arith.addf %642, %shuffleResult_126 : vector<1xf32>
          %shuffleResult_128, %valid_129 = gpu.shuffle  xor %643, %c2_i32, %c64_i32 : vector<1xf32>
          %644 = arith.addf %643, %shuffleResult_128 : vector<1xf32>
          %shuffleResult_130, %valid_131 = gpu.shuffle  xor %644, %c4_i32, %c64_i32 : vector<1xf32>
          %645 = arith.addf %644, %shuffleResult_130 : vector<1xf32>
          %shuffleResult_132, %valid_133 = gpu.shuffle  xor %645, %c8_i32, %c64_i32 : vector<1xf32>
          %646 = arith.addf %645, %shuffleResult_132 : vector<1xf32>
          %shuffleResult_134, %valid_135 = gpu.shuffle  xor %646, %c16_i32, %c64_i32 : vector<1xf32>
          %647 = arith.addf %646, %shuffleResult_134 : vector<1xf32>
          %shuffleResult_136, %valid_137 = gpu.shuffle  xor %647, %c32_i32, %c64_i32 : vector<1xf32>
          %648 = arith.addf %647, %shuffleResult_136 : vector<1xf32>
          %649 = arith.addf %648, %502 : vector<1xf32>
          %650 = arith.extf %218 : f16 to f32
          %651 = arith.mulf %650, %560 : f32
          %652 = vector.splat %651 : vector<1xf32>
          %shuffleResult_138, %valid_139 = gpu.shuffle  xor %652, %c1_i32, %c64_i32 : vector<1xf32>
          %653 = arith.addf %652, %shuffleResult_138 : vector<1xf32>
          %shuffleResult_140, %valid_141 = gpu.shuffle  xor %653, %c2_i32, %c64_i32 : vector<1xf32>
          %654 = arith.addf %653, %shuffleResult_140 : vector<1xf32>
          %shuffleResult_142, %valid_143 = gpu.shuffle  xor %654, %c4_i32, %c64_i32 : vector<1xf32>
          %655 = arith.addf %654, %shuffleResult_142 : vector<1xf32>
          %shuffleResult_144, %valid_145 = gpu.shuffle  xor %655, %c8_i32, %c64_i32 : vector<1xf32>
          %656 = arith.addf %655, %shuffleResult_144 : vector<1xf32>
          %shuffleResult_146, %valid_147 = gpu.shuffle  xor %656, %c16_i32, %c64_i32 : vector<1xf32>
          %657 = arith.addf %656, %shuffleResult_146 : vector<1xf32>
          %shuffleResult_148, %valid_149 = gpu.shuffle  xor %657, %c32_i32, %c64_i32 : vector<1xf32>
          %658 = arith.addf %657, %shuffleResult_148 : vector<1xf32>
          %659 = arith.addf %658, %503 : vector<1xf32>
          %660 = arith.extf %219 : f16 to f32
          %661 = arith.mulf %660, %560 : f32
          %662 = vector.splat %661 : vector<1xf32>
          %shuffleResult_150, %valid_151 = gpu.shuffle  xor %662, %c1_i32, %c64_i32 : vector<1xf32>
          %663 = arith.addf %662, %shuffleResult_150 : vector<1xf32>
          %shuffleResult_152, %valid_153 = gpu.shuffle  xor %663, %c2_i32, %c64_i32 : vector<1xf32>
          %664 = arith.addf %663, %shuffleResult_152 : vector<1xf32>
          %shuffleResult_154, %valid_155 = gpu.shuffle  xor %664, %c4_i32, %c64_i32 : vector<1xf32>
          %665 = arith.addf %664, %shuffleResult_154 : vector<1xf32>
          %shuffleResult_156, %valid_157 = gpu.shuffle  xor %665, %c8_i32, %c64_i32 : vector<1xf32>
          %666 = arith.addf %665, %shuffleResult_156 : vector<1xf32>
          %shuffleResult_158, %valid_159 = gpu.shuffle  xor %666, %c16_i32, %c64_i32 : vector<1xf32>
          %667 = arith.addf %666, %shuffleResult_158 : vector<1xf32>
          %shuffleResult_160, %valid_161 = gpu.shuffle  xor %667, %c32_i32, %c64_i32 : vector<1xf32>
          %668 = arith.addf %667, %shuffleResult_160 : vector<1xf32>
          %669 = arith.addf %668, %504 : vector<1xf32>
          %670 = arith.extf %220 : f16 to f32
          %671 = arith.mulf %670, %560 : f32
          %672 = vector.splat %671 : vector<1xf32>
          %shuffleResult_162, %valid_163 = gpu.shuffle  xor %672, %c1_i32, %c64_i32 : vector<1xf32>
          %673 = arith.addf %672, %shuffleResult_162 : vector<1xf32>
          %shuffleResult_164, %valid_165 = gpu.shuffle  xor %673, %c2_i32, %c64_i32 : vector<1xf32>
          %674 = arith.addf %673, %shuffleResult_164 : vector<1xf32>
          %shuffleResult_166, %valid_167 = gpu.shuffle  xor %674, %c4_i32, %c64_i32 : vector<1xf32>
          %675 = arith.addf %674, %shuffleResult_166 : vector<1xf32>
          %shuffleResult_168, %valid_169 = gpu.shuffle  xor %675, %c8_i32, %c64_i32 : vector<1xf32>
          %676 = arith.addf %675, %shuffleResult_168 : vector<1xf32>
          %shuffleResult_170, %valid_171 = gpu.shuffle  xor %676, %c16_i32, %c64_i32 : vector<1xf32>
          %677 = arith.addf %676, %shuffleResult_170 : vector<1xf32>
          %shuffleResult_172, %valid_173 = gpu.shuffle  xor %677, %c32_i32, %c64_i32 : vector<1xf32>
          %678 = arith.addf %677, %shuffleResult_172 : vector<1xf32>
          %679 = arith.addf %678, %505 : vector<1xf32>
          %680 = arith.extf %221 : f16 to f32
          %681 = arith.mulf %680, %560 : f32
          %682 = vector.splat %681 : vector<1xf32>
          %shuffleResult_174, %valid_175 = gpu.shuffle  xor %682, %c1_i32, %c64_i32 : vector<1xf32>
          %683 = arith.addf %682, %shuffleResult_174 : vector<1xf32>
          %shuffleResult_176, %valid_177 = gpu.shuffle  xor %683, %c2_i32, %c64_i32 : vector<1xf32>
          %684 = arith.addf %683, %shuffleResult_176 : vector<1xf32>
          %shuffleResult_178, %valid_179 = gpu.shuffle  xor %684, %c4_i32, %c64_i32 : vector<1xf32>
          %685 = arith.addf %684, %shuffleResult_178 : vector<1xf32>
          %shuffleResult_180, %valid_181 = gpu.shuffle  xor %685, %c8_i32, %c64_i32 : vector<1xf32>
          %686 = arith.addf %685, %shuffleResult_180 : vector<1xf32>
          %shuffleResult_182, %valid_183 = gpu.shuffle  xor %686, %c16_i32, %c64_i32 : vector<1xf32>
          %687 = arith.addf %686, %shuffleResult_182 : vector<1xf32>
          %shuffleResult_184, %valid_185 = gpu.shuffle  xor %687, %c32_i32, %c64_i32 : vector<1xf32>
          %688 = arith.addf %687, %shuffleResult_184 : vector<1xf32>
          %689 = arith.addf %688, %506 : vector<1xf32>
          %690 = arith.extf %222 : f16 to f32
          %691 = arith.mulf %690, %560 : f32
          %692 = vector.splat %691 : vector<1xf32>
          %shuffleResult_186, %valid_187 = gpu.shuffle  xor %692, %c1_i32, %c64_i32 : vector<1xf32>
          %693 = arith.addf %692, %shuffleResult_186 : vector<1xf32>
          %shuffleResult_188, %valid_189 = gpu.shuffle  xor %693, %c2_i32, %c64_i32 : vector<1xf32>
          %694 = arith.addf %693, %shuffleResult_188 : vector<1xf32>
          %shuffleResult_190, %valid_191 = gpu.shuffle  xor %694, %c4_i32, %c64_i32 : vector<1xf32>
          %695 = arith.addf %694, %shuffleResult_190 : vector<1xf32>
          %shuffleResult_192, %valid_193 = gpu.shuffle  xor %695, %c8_i32, %c64_i32 : vector<1xf32>
          %696 = arith.addf %695, %shuffleResult_192 : vector<1xf32>
          %shuffleResult_194, %valid_195 = gpu.shuffle  xor %696, %c16_i32, %c64_i32 : vector<1xf32>
          %697 = arith.addf %696, %shuffleResult_194 : vector<1xf32>
          %shuffleResult_196, %valid_197 = gpu.shuffle  xor %697, %c32_i32, %c64_i32 : vector<1xf32>
          %698 = arith.addf %697, %shuffleResult_196 : vector<1xf32>
          %699 = arith.addf %698, %507 : vector<1xf32>
          %700 = arith.extf %223 : f16 to f32
          %701 = arith.mulf %700, %560 : f32
          %702 = vector.splat %701 : vector<1xf32>
          %shuffleResult_198, %valid_199 = gpu.shuffle  xor %702, %c1_i32, %c64_i32 : vector<1xf32>
          %703 = arith.addf %702, %shuffleResult_198 : vector<1xf32>
          %shuffleResult_200, %valid_201 = gpu.shuffle  xor %703, %c2_i32, %c64_i32 : vector<1xf32>
          %704 = arith.addf %703, %shuffleResult_200 : vector<1xf32>
          %shuffleResult_202, %valid_203 = gpu.shuffle  xor %704, %c4_i32, %c64_i32 : vector<1xf32>
          %705 = arith.addf %704, %shuffleResult_202 : vector<1xf32>
          %shuffleResult_204, %valid_205 = gpu.shuffle  xor %705, %c8_i32, %c64_i32 : vector<1xf32>
          %706 = arith.addf %705, %shuffleResult_204 : vector<1xf32>
          %shuffleResult_206, %valid_207 = gpu.shuffle  xor %706, %c16_i32, %c64_i32 : vector<1xf32>
          %707 = arith.addf %706, %shuffleResult_206 : vector<1xf32>
          %shuffleResult_208, %valid_209 = gpu.shuffle  xor %707, %c32_i32, %c64_i32 : vector<1xf32>
          %708 = arith.addf %707, %shuffleResult_208 : vector<1xf32>
          %709 = arith.addf %708, %508 : vector<1xf32>
          %710 = arith.extf %224 : f16 to f32
          %711 = arith.mulf %710, %560 : f32
          %712 = vector.splat %711 : vector<1xf32>
          %shuffleResult_210, %valid_211 = gpu.shuffle  xor %712, %c1_i32, %c64_i32 : vector<1xf32>
          %713 = arith.addf %712, %shuffleResult_210 : vector<1xf32>
          %shuffleResult_212, %valid_213 = gpu.shuffle  xor %713, %c2_i32, %c64_i32 : vector<1xf32>
          %714 = arith.addf %713, %shuffleResult_212 : vector<1xf32>
          %shuffleResult_214, %valid_215 = gpu.shuffle  xor %714, %c4_i32, %c64_i32 : vector<1xf32>
          %715 = arith.addf %714, %shuffleResult_214 : vector<1xf32>
          %shuffleResult_216, %valid_217 = gpu.shuffle  xor %715, %c8_i32, %c64_i32 : vector<1xf32>
          %716 = arith.addf %715, %shuffleResult_216 : vector<1xf32>
          %shuffleResult_218, %valid_219 = gpu.shuffle  xor %716, %c16_i32, %c64_i32 : vector<1xf32>
          %717 = arith.addf %716, %shuffleResult_218 : vector<1xf32>
          %shuffleResult_220, %valid_221 = gpu.shuffle  xor %717, %c32_i32, %c64_i32 : vector<1xf32>
          %718 = arith.addf %717, %shuffleResult_220 : vector<1xf32>
          %719 = arith.addf %718, %509 : vector<1xf32>
          %720 = arith.extf %225 : f16 to f32
          %721 = arith.mulf %720, %560 : f32
          %722 = vector.splat %721 : vector<1xf32>
          %shuffleResult_222, %valid_223 = gpu.shuffle  xor %722, %c1_i32, %c64_i32 : vector<1xf32>
          %723 = arith.addf %722, %shuffleResult_222 : vector<1xf32>
          %shuffleResult_224, %valid_225 = gpu.shuffle  xor %723, %c2_i32, %c64_i32 : vector<1xf32>
          %724 = arith.addf %723, %shuffleResult_224 : vector<1xf32>
          %shuffleResult_226, %valid_227 = gpu.shuffle  xor %724, %c4_i32, %c64_i32 : vector<1xf32>
          %725 = arith.addf %724, %shuffleResult_226 : vector<1xf32>
          %shuffleResult_228, %valid_229 = gpu.shuffle  xor %725, %c8_i32, %c64_i32 : vector<1xf32>
          %726 = arith.addf %725, %shuffleResult_228 : vector<1xf32>
          %shuffleResult_230, %valid_231 = gpu.shuffle  xor %726, %c16_i32, %c64_i32 : vector<1xf32>
          %727 = arith.addf %726, %shuffleResult_230 : vector<1xf32>
          %shuffleResult_232, %valid_233 = gpu.shuffle  xor %727, %c32_i32, %c64_i32 : vector<1xf32>
          %728 = arith.addf %727, %shuffleResult_232 : vector<1xf32>
          %729 = arith.addf %728, %510 : vector<1xf32>
          %730 = arith.extf %226 : f16 to f32
          %731 = arith.mulf %730, %560 : f32
          %732 = vector.splat %731 : vector<1xf32>
          %shuffleResult_234, %valid_235 = gpu.shuffle  xor %732, %c1_i32, %c64_i32 : vector<1xf32>
          %733 = arith.addf %732, %shuffleResult_234 : vector<1xf32>
          %shuffleResult_236, %valid_237 = gpu.shuffle  xor %733, %c2_i32, %c64_i32 : vector<1xf32>
          %734 = arith.addf %733, %shuffleResult_236 : vector<1xf32>
          %shuffleResult_238, %valid_239 = gpu.shuffle  xor %734, %c4_i32, %c64_i32 : vector<1xf32>
          %735 = arith.addf %734, %shuffleResult_238 : vector<1xf32>
          %shuffleResult_240, %valid_241 = gpu.shuffle  xor %735, %c8_i32, %c64_i32 : vector<1xf32>
          %736 = arith.addf %735, %shuffleResult_240 : vector<1xf32>
          %shuffleResult_242, %valid_243 = gpu.shuffle  xor %736, %c16_i32, %c64_i32 : vector<1xf32>
          %737 = arith.addf %736, %shuffleResult_242 : vector<1xf32>
          %shuffleResult_244, %valid_245 = gpu.shuffle  xor %737, %c32_i32, %c64_i32 : vector<1xf32>
          %738 = arith.addf %737, %shuffleResult_244 : vector<1xf32>
          %739 = arith.addf %738, %511 : vector<1xf32>
          %740 = arith.extf %227 : f16 to f32
          %741 = arith.mulf %740, %560 : f32
          %742 = vector.splat %741 : vector<1xf32>
          %shuffleResult_246, %valid_247 = gpu.shuffle  xor %742, %c1_i32, %c64_i32 : vector<1xf32>
          %743 = arith.addf %742, %shuffleResult_246 : vector<1xf32>
          %shuffleResult_248, %valid_249 = gpu.shuffle  xor %743, %c2_i32, %c64_i32 : vector<1xf32>
          %744 = arith.addf %743, %shuffleResult_248 : vector<1xf32>
          %shuffleResult_250, %valid_251 = gpu.shuffle  xor %744, %c4_i32, %c64_i32 : vector<1xf32>
          %745 = arith.addf %744, %shuffleResult_250 : vector<1xf32>
          %shuffleResult_252, %valid_253 = gpu.shuffle  xor %745, %c8_i32, %c64_i32 : vector<1xf32>
          %746 = arith.addf %745, %shuffleResult_252 : vector<1xf32>
          %shuffleResult_254, %valid_255 = gpu.shuffle  xor %746, %c16_i32, %c64_i32 : vector<1xf32>
          %747 = arith.addf %746, %shuffleResult_254 : vector<1xf32>
          %shuffleResult_256, %valid_257 = gpu.shuffle  xor %747, %c32_i32, %c64_i32 : vector<1xf32>
          %748 = arith.addf %747, %shuffleResult_256 : vector<1xf32>
          %749 = arith.addf %748, %512 : vector<1xf32>
          %750 = arith.extf %228 : f16 to f32
          %751 = arith.mulf %750, %560 : f32
          %752 = vector.splat %751 : vector<1xf32>
          %shuffleResult_258, %valid_259 = gpu.shuffle  xor %752, %c1_i32, %c64_i32 : vector<1xf32>
          %753 = arith.addf %752, %shuffleResult_258 : vector<1xf32>
          %shuffleResult_260, %valid_261 = gpu.shuffle  xor %753, %c2_i32, %c64_i32 : vector<1xf32>
          %754 = arith.addf %753, %shuffleResult_260 : vector<1xf32>
          %shuffleResult_262, %valid_263 = gpu.shuffle  xor %754, %c4_i32, %c64_i32 : vector<1xf32>
          %755 = arith.addf %754, %shuffleResult_262 : vector<1xf32>
          %shuffleResult_264, %valid_265 = gpu.shuffle  xor %755, %c8_i32, %c64_i32 : vector<1xf32>
          %756 = arith.addf %755, %shuffleResult_264 : vector<1xf32>
          %shuffleResult_266, %valid_267 = gpu.shuffle  xor %756, %c16_i32, %c64_i32 : vector<1xf32>
          %757 = arith.addf %756, %shuffleResult_266 : vector<1xf32>
          %shuffleResult_268, %valid_269 = gpu.shuffle  xor %757, %c32_i32, %c64_i32 : vector<1xf32>
          %758 = arith.addf %757, %shuffleResult_268 : vector<1xf32>
          %759 = arith.addf %758, %513 : vector<1xf32>
          %760 = arith.extf %229 : f16 to f32
          %761 = arith.mulf %760, %560 : f32
          %762 = vector.splat %761 : vector<1xf32>
          %shuffleResult_270, %valid_271 = gpu.shuffle  xor %762, %c1_i32, %c64_i32 : vector<1xf32>
          %763 = arith.addf %762, %shuffleResult_270 : vector<1xf32>
          %shuffleResult_272, %valid_273 = gpu.shuffle  xor %763, %c2_i32, %c64_i32 : vector<1xf32>
          %764 = arith.addf %763, %shuffleResult_272 : vector<1xf32>
          %shuffleResult_274, %valid_275 = gpu.shuffle  xor %764, %c4_i32, %c64_i32 : vector<1xf32>
          %765 = arith.addf %764, %shuffleResult_274 : vector<1xf32>
          %shuffleResult_276, %valid_277 = gpu.shuffle  xor %765, %c8_i32, %c64_i32 : vector<1xf32>
          %766 = arith.addf %765, %shuffleResult_276 : vector<1xf32>
          %shuffleResult_278, %valid_279 = gpu.shuffle  xor %766, %c16_i32, %c64_i32 : vector<1xf32>
          %767 = arith.addf %766, %shuffleResult_278 : vector<1xf32>
          %shuffleResult_280, %valid_281 = gpu.shuffle  xor %767, %c32_i32, %c64_i32 : vector<1xf32>
          %768 = arith.addf %767, %shuffleResult_280 : vector<1xf32>
          %769 = arith.addf %768, %514 : vector<1xf32>
          %770 = arith.extf %230 : f16 to f32
          %771 = arith.mulf %770, %560 : f32
          %772 = vector.splat %771 : vector<1xf32>
          %shuffleResult_282, %valid_283 = gpu.shuffle  xor %772, %c1_i32, %c64_i32 : vector<1xf32>
          %773 = arith.addf %772, %shuffleResult_282 : vector<1xf32>
          %shuffleResult_284, %valid_285 = gpu.shuffle  xor %773, %c2_i32, %c64_i32 : vector<1xf32>
          %774 = arith.addf %773, %shuffleResult_284 : vector<1xf32>
          %shuffleResult_286, %valid_287 = gpu.shuffle  xor %774, %c4_i32, %c64_i32 : vector<1xf32>
          %775 = arith.addf %774, %shuffleResult_286 : vector<1xf32>
          %shuffleResult_288, %valid_289 = gpu.shuffle  xor %775, %c8_i32, %c64_i32 : vector<1xf32>
          %776 = arith.addf %775, %shuffleResult_288 : vector<1xf32>
          %shuffleResult_290, %valid_291 = gpu.shuffle  xor %776, %c16_i32, %c64_i32 : vector<1xf32>
          %777 = arith.addf %776, %shuffleResult_290 : vector<1xf32>
          %shuffleResult_292, %valid_293 = gpu.shuffle  xor %777, %c32_i32, %c64_i32 : vector<1xf32>
          %778 = arith.addf %777, %shuffleResult_292 : vector<1xf32>
          %779 = arith.addf %778, %515 : vector<1xf32>
          %780 = arith.extf %231 : f16 to f32
          %781 = arith.mulf %780, %560 : f32
          %782 = vector.splat %781 : vector<1xf32>
          %shuffleResult_294, %valid_295 = gpu.shuffle  xor %782, %c1_i32, %c64_i32 : vector<1xf32>
          %783 = arith.addf %782, %shuffleResult_294 : vector<1xf32>
          %shuffleResult_296, %valid_297 = gpu.shuffle  xor %783, %c2_i32, %c64_i32 : vector<1xf32>
          %784 = arith.addf %783, %shuffleResult_296 : vector<1xf32>
          %shuffleResult_298, %valid_299 = gpu.shuffle  xor %784, %c4_i32, %c64_i32 : vector<1xf32>
          %785 = arith.addf %784, %shuffleResult_298 : vector<1xf32>
          %shuffleResult_300, %valid_301 = gpu.shuffle  xor %785, %c8_i32, %c64_i32 : vector<1xf32>
          %786 = arith.addf %785, %shuffleResult_300 : vector<1xf32>
          %shuffleResult_302, %valid_303 = gpu.shuffle  xor %786, %c16_i32, %c64_i32 : vector<1xf32>
          %787 = arith.addf %786, %shuffleResult_302 : vector<1xf32>
          %shuffleResult_304, %valid_305 = gpu.shuffle  xor %787, %c32_i32, %c64_i32 : vector<1xf32>
          %788 = arith.addf %787, %shuffleResult_304 : vector<1xf32>
          %789 = arith.addf %788, %516 : vector<1xf32>
          %790 = arith.extf %232 : f16 to f32
          %791 = arith.mulf %790, %560 : f32
          %792 = vector.splat %791 : vector<1xf32>
          %shuffleResult_306, %valid_307 = gpu.shuffle  xor %792, %c1_i32, %c64_i32 : vector<1xf32>
          %793 = arith.addf %792, %shuffleResult_306 : vector<1xf32>
          %shuffleResult_308, %valid_309 = gpu.shuffle  xor %793, %c2_i32, %c64_i32 : vector<1xf32>
          %794 = arith.addf %793, %shuffleResult_308 : vector<1xf32>
          %shuffleResult_310, %valid_311 = gpu.shuffle  xor %794, %c4_i32, %c64_i32 : vector<1xf32>
          %795 = arith.addf %794, %shuffleResult_310 : vector<1xf32>
          %shuffleResult_312, %valid_313 = gpu.shuffle  xor %795, %c8_i32, %c64_i32 : vector<1xf32>
          %796 = arith.addf %795, %shuffleResult_312 : vector<1xf32>
          %shuffleResult_314, %valid_315 = gpu.shuffle  xor %796, %c16_i32, %c64_i32 : vector<1xf32>
          %797 = arith.addf %796, %shuffleResult_314 : vector<1xf32>
          %shuffleResult_316, %valid_317 = gpu.shuffle  xor %797, %c32_i32, %c64_i32 : vector<1xf32>
          %798 = arith.addf %797, %shuffleResult_316 : vector<1xf32>
          %799 = arith.addf %798, %517 : vector<1xf32>
          %800 = arith.extf %233 : f16 to f32
          %801 = arith.mulf %800, %560 : f32
          %802 = vector.splat %801 : vector<1xf32>
          %shuffleResult_318, %valid_319 = gpu.shuffle  xor %802, %c1_i32, %c64_i32 : vector<1xf32>
          %803 = arith.addf %802, %shuffleResult_318 : vector<1xf32>
          %shuffleResult_320, %valid_321 = gpu.shuffle  xor %803, %c2_i32, %c64_i32 : vector<1xf32>
          %804 = arith.addf %803, %shuffleResult_320 : vector<1xf32>
          %shuffleResult_322, %valid_323 = gpu.shuffle  xor %804, %c4_i32, %c64_i32 : vector<1xf32>
          %805 = arith.addf %804, %shuffleResult_322 : vector<1xf32>
          %shuffleResult_324, %valid_325 = gpu.shuffle  xor %805, %c8_i32, %c64_i32 : vector<1xf32>
          %806 = arith.addf %805, %shuffleResult_324 : vector<1xf32>
          %shuffleResult_326, %valid_327 = gpu.shuffle  xor %806, %c16_i32, %c64_i32 : vector<1xf32>
          %807 = arith.addf %806, %shuffleResult_326 : vector<1xf32>
          %shuffleResult_328, %valid_329 = gpu.shuffle  xor %807, %c32_i32, %c64_i32 : vector<1xf32>
          %808 = arith.addf %807, %shuffleResult_328 : vector<1xf32>
          %809 = arith.addf %808, %518 : vector<1xf32>
          %810 = arith.extf %234 : f16 to f32
          %811 = arith.mulf %810, %560 : f32
          %812 = vector.splat %811 : vector<1xf32>
          %shuffleResult_330, %valid_331 = gpu.shuffle  xor %812, %c1_i32, %c64_i32 : vector<1xf32>
          %813 = arith.addf %812, %shuffleResult_330 : vector<1xf32>
          %shuffleResult_332, %valid_333 = gpu.shuffle  xor %813, %c2_i32, %c64_i32 : vector<1xf32>
          %814 = arith.addf %813, %shuffleResult_332 : vector<1xf32>
          %shuffleResult_334, %valid_335 = gpu.shuffle  xor %814, %c4_i32, %c64_i32 : vector<1xf32>
          %815 = arith.addf %814, %shuffleResult_334 : vector<1xf32>
          %shuffleResult_336, %valid_337 = gpu.shuffle  xor %815, %c8_i32, %c64_i32 : vector<1xf32>
          %816 = arith.addf %815, %shuffleResult_336 : vector<1xf32>
          %shuffleResult_338, %valid_339 = gpu.shuffle  xor %816, %c16_i32, %c64_i32 : vector<1xf32>
          %817 = arith.addf %816, %shuffleResult_338 : vector<1xf32>
          %shuffleResult_340, %valid_341 = gpu.shuffle  xor %817, %c32_i32, %c64_i32 : vector<1xf32>
          %818 = arith.addf %817, %shuffleResult_340 : vector<1xf32>
          %819 = arith.addf %818, %519 : vector<1xf32>
          %820 = arith.extf %235 : f16 to f32
          %821 = arith.mulf %820, %560 : f32
          %822 = vector.splat %821 : vector<1xf32>
          %shuffleResult_342, %valid_343 = gpu.shuffle  xor %822, %c1_i32, %c64_i32 : vector<1xf32>
          %823 = arith.addf %822, %shuffleResult_342 : vector<1xf32>
          %shuffleResult_344, %valid_345 = gpu.shuffle  xor %823, %c2_i32, %c64_i32 : vector<1xf32>
          %824 = arith.addf %823, %shuffleResult_344 : vector<1xf32>
          %shuffleResult_346, %valid_347 = gpu.shuffle  xor %824, %c4_i32, %c64_i32 : vector<1xf32>
          %825 = arith.addf %824, %shuffleResult_346 : vector<1xf32>
          %shuffleResult_348, %valid_349 = gpu.shuffle  xor %825, %c8_i32, %c64_i32 : vector<1xf32>
          %826 = arith.addf %825, %shuffleResult_348 : vector<1xf32>
          %shuffleResult_350, %valid_351 = gpu.shuffle  xor %826, %c16_i32, %c64_i32 : vector<1xf32>
          %827 = arith.addf %826, %shuffleResult_350 : vector<1xf32>
          %shuffleResult_352, %valid_353 = gpu.shuffle  xor %827, %c32_i32, %c64_i32 : vector<1xf32>
          %828 = arith.addf %827, %shuffleResult_352 : vector<1xf32>
          %829 = arith.addf %828, %520 : vector<1xf32>
          %830 = arith.extf %236 : f16 to f32
          %831 = arith.mulf %830, %560 : f32
          %832 = vector.splat %831 : vector<1xf32>
          %shuffleResult_354, %valid_355 = gpu.shuffle  xor %832, %c1_i32, %c64_i32 : vector<1xf32>
          %833 = arith.addf %832, %shuffleResult_354 : vector<1xf32>
          %shuffleResult_356, %valid_357 = gpu.shuffle  xor %833, %c2_i32, %c64_i32 : vector<1xf32>
          %834 = arith.addf %833, %shuffleResult_356 : vector<1xf32>
          %shuffleResult_358, %valid_359 = gpu.shuffle  xor %834, %c4_i32, %c64_i32 : vector<1xf32>
          %835 = arith.addf %834, %shuffleResult_358 : vector<1xf32>
          %shuffleResult_360, %valid_361 = gpu.shuffle  xor %835, %c8_i32, %c64_i32 : vector<1xf32>
          %836 = arith.addf %835, %shuffleResult_360 : vector<1xf32>
          %shuffleResult_362, %valid_363 = gpu.shuffle  xor %836, %c16_i32, %c64_i32 : vector<1xf32>
          %837 = arith.addf %836, %shuffleResult_362 : vector<1xf32>
          %shuffleResult_364, %valid_365 = gpu.shuffle  xor %837, %c32_i32, %c64_i32 : vector<1xf32>
          %838 = arith.addf %837, %shuffleResult_364 : vector<1xf32>
          %839 = arith.addf %838, %521 : vector<1xf32>
          %840 = arith.extf %237 : f16 to f32
          %841 = arith.mulf %840, %560 : f32
          %842 = vector.splat %841 : vector<1xf32>
          %shuffleResult_366, %valid_367 = gpu.shuffle  xor %842, %c1_i32, %c64_i32 : vector<1xf32>
          %843 = arith.addf %842, %shuffleResult_366 : vector<1xf32>
          %shuffleResult_368, %valid_369 = gpu.shuffle  xor %843, %c2_i32, %c64_i32 : vector<1xf32>
          %844 = arith.addf %843, %shuffleResult_368 : vector<1xf32>
          %shuffleResult_370, %valid_371 = gpu.shuffle  xor %844, %c4_i32, %c64_i32 : vector<1xf32>
          %845 = arith.addf %844, %shuffleResult_370 : vector<1xf32>
          %shuffleResult_372, %valid_373 = gpu.shuffle  xor %845, %c8_i32, %c64_i32 : vector<1xf32>
          %846 = arith.addf %845, %shuffleResult_372 : vector<1xf32>
          %shuffleResult_374, %valid_375 = gpu.shuffle  xor %846, %c16_i32, %c64_i32 : vector<1xf32>
          %847 = arith.addf %846, %shuffleResult_374 : vector<1xf32>
          %shuffleResult_376, %valid_377 = gpu.shuffle  xor %847, %c32_i32, %c64_i32 : vector<1xf32>
          %848 = arith.addf %847, %shuffleResult_376 : vector<1xf32>
          %849 = arith.addf %848, %522 : vector<1xf32>
          %850 = arith.extf %238 : f16 to f32
          %851 = arith.mulf %850, %560 : f32
          %852 = vector.splat %851 : vector<1xf32>
          %shuffleResult_378, %valid_379 = gpu.shuffle  xor %852, %c1_i32, %c64_i32 : vector<1xf32>
          %853 = arith.addf %852, %shuffleResult_378 : vector<1xf32>
          %shuffleResult_380, %valid_381 = gpu.shuffle  xor %853, %c2_i32, %c64_i32 : vector<1xf32>
          %854 = arith.addf %853, %shuffleResult_380 : vector<1xf32>
          %shuffleResult_382, %valid_383 = gpu.shuffle  xor %854, %c4_i32, %c64_i32 : vector<1xf32>
          %855 = arith.addf %854, %shuffleResult_382 : vector<1xf32>
          %shuffleResult_384, %valid_385 = gpu.shuffle  xor %855, %c8_i32, %c64_i32 : vector<1xf32>
          %856 = arith.addf %855, %shuffleResult_384 : vector<1xf32>
          %shuffleResult_386, %valid_387 = gpu.shuffle  xor %856, %c16_i32, %c64_i32 : vector<1xf32>
          %857 = arith.addf %856, %shuffleResult_386 : vector<1xf32>
          %shuffleResult_388, %valid_389 = gpu.shuffle  xor %857, %c32_i32, %c64_i32 : vector<1xf32>
          %858 = arith.addf %857, %shuffleResult_388 : vector<1xf32>
          %859 = arith.addf %858, %523 : vector<1xf32>
          %860 = arith.extf %239 : f16 to f32
          %861 = arith.mulf %860, %560 : f32
          %862 = vector.splat %861 : vector<1xf32>
          %shuffleResult_390, %valid_391 = gpu.shuffle  xor %862, %c1_i32, %c64_i32 : vector<1xf32>
          %863 = arith.addf %862, %shuffleResult_390 : vector<1xf32>
          %shuffleResult_392, %valid_393 = gpu.shuffle  xor %863, %c2_i32, %c64_i32 : vector<1xf32>
          %864 = arith.addf %863, %shuffleResult_392 : vector<1xf32>
          %shuffleResult_394, %valid_395 = gpu.shuffle  xor %864, %c4_i32, %c64_i32 : vector<1xf32>
          %865 = arith.addf %864, %shuffleResult_394 : vector<1xf32>
          %shuffleResult_396, %valid_397 = gpu.shuffle  xor %865, %c8_i32, %c64_i32 : vector<1xf32>
          %866 = arith.addf %865, %shuffleResult_396 : vector<1xf32>
          %shuffleResult_398, %valid_399 = gpu.shuffle  xor %866, %c16_i32, %c64_i32 : vector<1xf32>
          %867 = arith.addf %866, %shuffleResult_398 : vector<1xf32>
          %shuffleResult_400, %valid_401 = gpu.shuffle  xor %867, %c32_i32, %c64_i32 : vector<1xf32>
          %868 = arith.addf %867, %shuffleResult_400 : vector<1xf32>
          %869 = arith.addf %868, %524 : vector<1xf32>
          %870 = arith.extf %240 : f16 to f32
          %871 = arith.mulf %870, %560 : f32
          %872 = vector.splat %871 : vector<1xf32>
          %shuffleResult_402, %valid_403 = gpu.shuffle  xor %872, %c1_i32, %c64_i32 : vector<1xf32>
          %873 = arith.addf %872, %shuffleResult_402 : vector<1xf32>
          %shuffleResult_404, %valid_405 = gpu.shuffle  xor %873, %c2_i32, %c64_i32 : vector<1xf32>
          %874 = arith.addf %873, %shuffleResult_404 : vector<1xf32>
          %shuffleResult_406, %valid_407 = gpu.shuffle  xor %874, %c4_i32, %c64_i32 : vector<1xf32>
          %875 = arith.addf %874, %shuffleResult_406 : vector<1xf32>
          %shuffleResult_408, %valid_409 = gpu.shuffle  xor %875, %c8_i32, %c64_i32 : vector<1xf32>
          %876 = arith.addf %875, %shuffleResult_408 : vector<1xf32>
          %shuffleResult_410, %valid_411 = gpu.shuffle  xor %876, %c16_i32, %c64_i32 : vector<1xf32>
          %877 = arith.addf %876, %shuffleResult_410 : vector<1xf32>
          %shuffleResult_412, %valid_413 = gpu.shuffle  xor %877, %c32_i32, %c64_i32 : vector<1xf32>
          %878 = arith.addf %877, %shuffleResult_412 : vector<1xf32>
          %879 = arith.addf %878, %525 : vector<1xf32>
          %880 = arith.extf %241 : f16 to f32
          %881 = arith.mulf %880, %560 : f32
          %882 = vector.splat %881 : vector<1xf32>
          %shuffleResult_414, %valid_415 = gpu.shuffle  xor %882, %c1_i32, %c64_i32 : vector<1xf32>
          %883 = arith.addf %882, %shuffleResult_414 : vector<1xf32>
          %shuffleResult_416, %valid_417 = gpu.shuffle  xor %883, %c2_i32, %c64_i32 : vector<1xf32>
          %884 = arith.addf %883, %shuffleResult_416 : vector<1xf32>
          %shuffleResult_418, %valid_419 = gpu.shuffle  xor %884, %c4_i32, %c64_i32 : vector<1xf32>
          %885 = arith.addf %884, %shuffleResult_418 : vector<1xf32>
          %shuffleResult_420, %valid_421 = gpu.shuffle  xor %885, %c8_i32, %c64_i32 : vector<1xf32>
          %886 = arith.addf %885, %shuffleResult_420 : vector<1xf32>
          %shuffleResult_422, %valid_423 = gpu.shuffle  xor %886, %c16_i32, %c64_i32 : vector<1xf32>
          %887 = arith.addf %886, %shuffleResult_422 : vector<1xf32>
          %shuffleResult_424, %valid_425 = gpu.shuffle  xor %887, %c32_i32, %c64_i32 : vector<1xf32>
          %888 = arith.addf %887, %shuffleResult_424 : vector<1xf32>
          %889 = arith.addf %888, %526 : vector<1xf32>
          %890 = arith.extf %242 : f16 to f32
          %891 = arith.mulf %890, %560 : f32
          %892 = vector.splat %891 : vector<1xf32>
          %shuffleResult_426, %valid_427 = gpu.shuffle  xor %892, %c1_i32, %c64_i32 : vector<1xf32>
          %893 = arith.addf %892, %shuffleResult_426 : vector<1xf32>
          %shuffleResult_428, %valid_429 = gpu.shuffle  xor %893, %c2_i32, %c64_i32 : vector<1xf32>
          %894 = arith.addf %893, %shuffleResult_428 : vector<1xf32>
          %shuffleResult_430, %valid_431 = gpu.shuffle  xor %894, %c4_i32, %c64_i32 : vector<1xf32>
          %895 = arith.addf %894, %shuffleResult_430 : vector<1xf32>
          %shuffleResult_432, %valid_433 = gpu.shuffle  xor %895, %c8_i32, %c64_i32 : vector<1xf32>
          %896 = arith.addf %895, %shuffleResult_432 : vector<1xf32>
          %shuffleResult_434, %valid_435 = gpu.shuffle  xor %896, %c16_i32, %c64_i32 : vector<1xf32>
          %897 = arith.addf %896, %shuffleResult_434 : vector<1xf32>
          %shuffleResult_436, %valid_437 = gpu.shuffle  xor %897, %c32_i32, %c64_i32 : vector<1xf32>
          %898 = arith.addf %897, %shuffleResult_436 : vector<1xf32>
          %899 = arith.addf %898, %527 : vector<1xf32>
          %900 = arith.extf %243 : f16 to f32
          %901 = arith.mulf %900, %560 : f32
          %902 = vector.splat %901 : vector<1xf32>
          %shuffleResult_438, %valid_439 = gpu.shuffle  xor %902, %c1_i32, %c64_i32 : vector<1xf32>
          %903 = arith.addf %902, %shuffleResult_438 : vector<1xf32>
          %shuffleResult_440, %valid_441 = gpu.shuffle  xor %903, %c2_i32, %c64_i32 : vector<1xf32>
          %904 = arith.addf %903, %shuffleResult_440 : vector<1xf32>
          %shuffleResult_442, %valid_443 = gpu.shuffle  xor %904, %c4_i32, %c64_i32 : vector<1xf32>
          %905 = arith.addf %904, %shuffleResult_442 : vector<1xf32>
          %shuffleResult_444, %valid_445 = gpu.shuffle  xor %905, %c8_i32, %c64_i32 : vector<1xf32>
          %906 = arith.addf %905, %shuffleResult_444 : vector<1xf32>
          %shuffleResult_446, %valid_447 = gpu.shuffle  xor %906, %c16_i32, %c64_i32 : vector<1xf32>
          %907 = arith.addf %906, %shuffleResult_446 : vector<1xf32>
          %shuffleResult_448, %valid_449 = gpu.shuffle  xor %907, %c32_i32, %c64_i32 : vector<1xf32>
          %908 = arith.addf %907, %shuffleResult_448 : vector<1xf32>
          %909 = arith.addf %908, %528 : vector<1xf32>
          %910 = arith.extf %244 : f16 to f32
          %911 = arith.mulf %910, %560 : f32
          %912 = vector.splat %911 : vector<1xf32>
          %shuffleResult_450, %valid_451 = gpu.shuffle  xor %912, %c1_i32, %c64_i32 : vector<1xf32>
          %913 = arith.addf %912, %shuffleResult_450 : vector<1xf32>
          %shuffleResult_452, %valid_453 = gpu.shuffle  xor %913, %c2_i32, %c64_i32 : vector<1xf32>
          %914 = arith.addf %913, %shuffleResult_452 : vector<1xf32>
          %shuffleResult_454, %valid_455 = gpu.shuffle  xor %914, %c4_i32, %c64_i32 : vector<1xf32>
          %915 = arith.addf %914, %shuffleResult_454 : vector<1xf32>
          %shuffleResult_456, %valid_457 = gpu.shuffle  xor %915, %c8_i32, %c64_i32 : vector<1xf32>
          %916 = arith.addf %915, %shuffleResult_456 : vector<1xf32>
          %shuffleResult_458, %valid_459 = gpu.shuffle  xor %916, %c16_i32, %c64_i32 : vector<1xf32>
          %917 = arith.addf %916, %shuffleResult_458 : vector<1xf32>
          %shuffleResult_460, %valid_461 = gpu.shuffle  xor %917, %c32_i32, %c64_i32 : vector<1xf32>
          %918 = arith.addf %917, %shuffleResult_460 : vector<1xf32>
          %919 = arith.addf %918, %529 : vector<1xf32>
          %920 = arith.extf %245 : f16 to f32
          %921 = arith.mulf %920, %560 : f32
          %922 = vector.splat %921 : vector<1xf32>
          %shuffleResult_462, %valid_463 = gpu.shuffle  xor %922, %c1_i32, %c64_i32 : vector<1xf32>
          %923 = arith.addf %922, %shuffleResult_462 : vector<1xf32>
          %shuffleResult_464, %valid_465 = gpu.shuffle  xor %923, %c2_i32, %c64_i32 : vector<1xf32>
          %924 = arith.addf %923, %shuffleResult_464 : vector<1xf32>
          %shuffleResult_466, %valid_467 = gpu.shuffle  xor %924, %c4_i32, %c64_i32 : vector<1xf32>
          %925 = arith.addf %924, %shuffleResult_466 : vector<1xf32>
          %shuffleResult_468, %valid_469 = gpu.shuffle  xor %925, %c8_i32, %c64_i32 : vector<1xf32>
          %926 = arith.addf %925, %shuffleResult_468 : vector<1xf32>
          %shuffleResult_470, %valid_471 = gpu.shuffle  xor %926, %c16_i32, %c64_i32 : vector<1xf32>
          %927 = arith.addf %926, %shuffleResult_470 : vector<1xf32>
          %shuffleResult_472, %valid_473 = gpu.shuffle  xor %927, %c32_i32, %c64_i32 : vector<1xf32>
          %928 = arith.addf %927, %shuffleResult_472 : vector<1xf32>
          %929 = arith.addf %928, %530 : vector<1xf32>
          %930 = arith.extf %246 : f16 to f32
          %931 = arith.mulf %930, %560 : f32
          %932 = vector.splat %931 : vector<1xf32>
          %shuffleResult_474, %valid_475 = gpu.shuffle  xor %932, %c1_i32, %c64_i32 : vector<1xf32>
          %933 = arith.addf %932, %shuffleResult_474 : vector<1xf32>
          %shuffleResult_476, %valid_477 = gpu.shuffle  xor %933, %c2_i32, %c64_i32 : vector<1xf32>
          %934 = arith.addf %933, %shuffleResult_476 : vector<1xf32>
          %shuffleResult_478, %valid_479 = gpu.shuffle  xor %934, %c4_i32, %c64_i32 : vector<1xf32>
          %935 = arith.addf %934, %shuffleResult_478 : vector<1xf32>
          %shuffleResult_480, %valid_481 = gpu.shuffle  xor %935, %c8_i32, %c64_i32 : vector<1xf32>
          %936 = arith.addf %935, %shuffleResult_480 : vector<1xf32>
          %shuffleResult_482, %valid_483 = gpu.shuffle  xor %936, %c16_i32, %c64_i32 : vector<1xf32>
          %937 = arith.addf %936, %shuffleResult_482 : vector<1xf32>
          %shuffleResult_484, %valid_485 = gpu.shuffle  xor %937, %c32_i32, %c64_i32 : vector<1xf32>
          %938 = arith.addf %937, %shuffleResult_484 : vector<1xf32>
          %939 = arith.addf %938, %531 : vector<1xf32>
          %940 = arith.extf %247 : f16 to f32
          %941 = arith.mulf %940, %560 : f32
          %942 = vector.splat %941 : vector<1xf32>
          %shuffleResult_486, %valid_487 = gpu.shuffle  xor %942, %c1_i32, %c64_i32 : vector<1xf32>
          %943 = arith.addf %942, %shuffleResult_486 : vector<1xf32>
          %shuffleResult_488, %valid_489 = gpu.shuffle  xor %943, %c2_i32, %c64_i32 : vector<1xf32>
          %944 = arith.addf %943, %shuffleResult_488 : vector<1xf32>
          %shuffleResult_490, %valid_491 = gpu.shuffle  xor %944, %c4_i32, %c64_i32 : vector<1xf32>
          %945 = arith.addf %944, %shuffleResult_490 : vector<1xf32>
          %shuffleResult_492, %valid_493 = gpu.shuffle  xor %945, %c8_i32, %c64_i32 : vector<1xf32>
          %946 = arith.addf %945, %shuffleResult_492 : vector<1xf32>
          %shuffleResult_494, %valid_495 = gpu.shuffle  xor %946, %c16_i32, %c64_i32 : vector<1xf32>
          %947 = arith.addf %946, %shuffleResult_494 : vector<1xf32>
          %shuffleResult_496, %valid_497 = gpu.shuffle  xor %947, %c32_i32, %c64_i32 : vector<1xf32>
          %948 = arith.addf %947, %shuffleResult_496 : vector<1xf32>
          %949 = arith.addf %948, %532 : vector<1xf32>
          %950 = arith.extf %248 : f16 to f32
          %951 = arith.mulf %950, %560 : f32
          %952 = vector.splat %951 : vector<1xf32>
          %shuffleResult_498, %valid_499 = gpu.shuffle  xor %952, %c1_i32, %c64_i32 : vector<1xf32>
          %953 = arith.addf %952, %shuffleResult_498 : vector<1xf32>
          %shuffleResult_500, %valid_501 = gpu.shuffle  xor %953, %c2_i32, %c64_i32 : vector<1xf32>
          %954 = arith.addf %953, %shuffleResult_500 : vector<1xf32>
          %shuffleResult_502, %valid_503 = gpu.shuffle  xor %954, %c4_i32, %c64_i32 : vector<1xf32>
          %955 = arith.addf %954, %shuffleResult_502 : vector<1xf32>
          %shuffleResult_504, %valid_505 = gpu.shuffle  xor %955, %c8_i32, %c64_i32 : vector<1xf32>
          %956 = arith.addf %955, %shuffleResult_504 : vector<1xf32>
          %shuffleResult_506, %valid_507 = gpu.shuffle  xor %956, %c16_i32, %c64_i32 : vector<1xf32>
          %957 = arith.addf %956, %shuffleResult_506 : vector<1xf32>
          %shuffleResult_508, %valid_509 = gpu.shuffle  xor %957, %c32_i32, %c64_i32 : vector<1xf32>
          %958 = arith.addf %957, %shuffleResult_508 : vector<1xf32>
          %959 = arith.addf %958, %533 : vector<1xf32>
          %960 = arith.extf %249 : f16 to f32
          %961 = arith.mulf %960, %560 : f32
          %962 = vector.splat %961 : vector<1xf32>
          %shuffleResult_510, %valid_511 = gpu.shuffle  xor %962, %c1_i32, %c64_i32 : vector<1xf32>
          %963 = arith.addf %962, %shuffleResult_510 : vector<1xf32>
          %shuffleResult_512, %valid_513 = gpu.shuffle  xor %963, %c2_i32, %c64_i32 : vector<1xf32>
          %964 = arith.addf %963, %shuffleResult_512 : vector<1xf32>
          %shuffleResult_514, %valid_515 = gpu.shuffle  xor %964, %c4_i32, %c64_i32 : vector<1xf32>
          %965 = arith.addf %964, %shuffleResult_514 : vector<1xf32>
          %shuffleResult_516, %valid_517 = gpu.shuffle  xor %965, %c8_i32, %c64_i32 : vector<1xf32>
          %966 = arith.addf %965, %shuffleResult_516 : vector<1xf32>
          %shuffleResult_518, %valid_519 = gpu.shuffle  xor %966, %c16_i32, %c64_i32 : vector<1xf32>
          %967 = arith.addf %966, %shuffleResult_518 : vector<1xf32>
          %shuffleResult_520, %valid_521 = gpu.shuffle  xor %967, %c32_i32, %c64_i32 : vector<1xf32>
          %968 = arith.addf %967, %shuffleResult_520 : vector<1xf32>
          %969 = arith.addf %968, %534 : vector<1xf32>
          %970 = arith.extf %250 : f16 to f32
          %971 = arith.mulf %970, %560 : f32
          %972 = vector.splat %971 : vector<1xf32>
          %shuffleResult_522, %valid_523 = gpu.shuffle  xor %972, %c1_i32, %c64_i32 : vector<1xf32>
          %973 = arith.addf %972, %shuffleResult_522 : vector<1xf32>
          %shuffleResult_524, %valid_525 = gpu.shuffle  xor %973, %c2_i32, %c64_i32 : vector<1xf32>
          %974 = arith.addf %973, %shuffleResult_524 : vector<1xf32>
          %shuffleResult_526, %valid_527 = gpu.shuffle  xor %974, %c4_i32, %c64_i32 : vector<1xf32>
          %975 = arith.addf %974, %shuffleResult_526 : vector<1xf32>
          %shuffleResult_528, %valid_529 = gpu.shuffle  xor %975, %c8_i32, %c64_i32 : vector<1xf32>
          %976 = arith.addf %975, %shuffleResult_528 : vector<1xf32>
          %shuffleResult_530, %valid_531 = gpu.shuffle  xor %976, %c16_i32, %c64_i32 : vector<1xf32>
          %977 = arith.addf %976, %shuffleResult_530 : vector<1xf32>
          %shuffleResult_532, %valid_533 = gpu.shuffle  xor %977, %c32_i32, %c64_i32 : vector<1xf32>
          %978 = arith.addf %977, %shuffleResult_532 : vector<1xf32>
          %979 = arith.addf %978, %535 : vector<1xf32>
          %980 = arith.extf %251 : f16 to f32
          %981 = arith.mulf %980, %560 : f32
          %982 = vector.splat %981 : vector<1xf32>
          %shuffleResult_534, %valid_535 = gpu.shuffle  xor %982, %c1_i32, %c64_i32 : vector<1xf32>
          %983 = arith.addf %982, %shuffleResult_534 : vector<1xf32>
          %shuffleResult_536, %valid_537 = gpu.shuffle  xor %983, %c2_i32, %c64_i32 : vector<1xf32>
          %984 = arith.addf %983, %shuffleResult_536 : vector<1xf32>
          %shuffleResult_538, %valid_539 = gpu.shuffle  xor %984, %c4_i32, %c64_i32 : vector<1xf32>
          %985 = arith.addf %984, %shuffleResult_538 : vector<1xf32>
          %shuffleResult_540, %valid_541 = gpu.shuffle  xor %985, %c8_i32, %c64_i32 : vector<1xf32>
          %986 = arith.addf %985, %shuffleResult_540 : vector<1xf32>
          %shuffleResult_542, %valid_543 = gpu.shuffle  xor %986, %c16_i32, %c64_i32 : vector<1xf32>
          %987 = arith.addf %986, %shuffleResult_542 : vector<1xf32>
          %shuffleResult_544, %valid_545 = gpu.shuffle  xor %987, %c32_i32, %c64_i32 : vector<1xf32>
          %988 = arith.addf %987, %shuffleResult_544 : vector<1xf32>
          %989 = arith.addf %988, %536 : vector<1xf32>
          %990 = arith.extf %252 : f16 to f32
          %991 = arith.mulf %990, %560 : f32
          %992 = vector.splat %991 : vector<1xf32>
          %shuffleResult_546, %valid_547 = gpu.shuffle  xor %992, %c1_i32, %c64_i32 : vector<1xf32>
          %993 = arith.addf %992, %shuffleResult_546 : vector<1xf32>
          %shuffleResult_548, %valid_549 = gpu.shuffle  xor %993, %c2_i32, %c64_i32 : vector<1xf32>
          %994 = arith.addf %993, %shuffleResult_548 : vector<1xf32>
          %shuffleResult_550, %valid_551 = gpu.shuffle  xor %994, %c4_i32, %c64_i32 : vector<1xf32>
          %995 = arith.addf %994, %shuffleResult_550 : vector<1xf32>
          %shuffleResult_552, %valid_553 = gpu.shuffle  xor %995, %c8_i32, %c64_i32 : vector<1xf32>
          %996 = arith.addf %995, %shuffleResult_552 : vector<1xf32>
          %shuffleResult_554, %valid_555 = gpu.shuffle  xor %996, %c16_i32, %c64_i32 : vector<1xf32>
          %997 = arith.addf %996, %shuffleResult_554 : vector<1xf32>
          %shuffleResult_556, %valid_557 = gpu.shuffle  xor %997, %c32_i32, %c64_i32 : vector<1xf32>
          %998 = arith.addf %997, %shuffleResult_556 : vector<1xf32>
          %999 = arith.addf %998, %537 : vector<1xf32>
          %1000 = arith.extf %253 : f16 to f32
          %1001 = arith.mulf %1000, %560 : f32
          %1002 = vector.splat %1001 : vector<1xf32>
          %shuffleResult_558, %valid_559 = gpu.shuffle  xor %1002, %c1_i32, %c64_i32 : vector<1xf32>
          %1003 = arith.addf %1002, %shuffleResult_558 : vector<1xf32>
          %shuffleResult_560, %valid_561 = gpu.shuffle  xor %1003, %c2_i32, %c64_i32 : vector<1xf32>
          %1004 = arith.addf %1003, %shuffleResult_560 : vector<1xf32>
          %shuffleResult_562, %valid_563 = gpu.shuffle  xor %1004, %c4_i32, %c64_i32 : vector<1xf32>
          %1005 = arith.addf %1004, %shuffleResult_562 : vector<1xf32>
          %shuffleResult_564, %valid_565 = gpu.shuffle  xor %1005, %c8_i32, %c64_i32 : vector<1xf32>
          %1006 = arith.addf %1005, %shuffleResult_564 : vector<1xf32>
          %shuffleResult_566, %valid_567 = gpu.shuffle  xor %1006, %c16_i32, %c64_i32 : vector<1xf32>
          %1007 = arith.addf %1006, %shuffleResult_566 : vector<1xf32>
          %shuffleResult_568, %valid_569 = gpu.shuffle  xor %1007, %c32_i32, %c64_i32 : vector<1xf32>
          %1008 = arith.addf %1007, %shuffleResult_568 : vector<1xf32>
          %1009 = arith.addf %1008, %538 : vector<1xf32>
          %1010 = arith.extf %254 : f16 to f32
          %1011 = arith.mulf %1010, %560 : f32
          %1012 = vector.splat %1011 : vector<1xf32>
          %shuffleResult_570, %valid_571 = gpu.shuffle  xor %1012, %c1_i32, %c64_i32 : vector<1xf32>
          %1013 = arith.addf %1012, %shuffleResult_570 : vector<1xf32>
          %shuffleResult_572, %valid_573 = gpu.shuffle  xor %1013, %c2_i32, %c64_i32 : vector<1xf32>
          %1014 = arith.addf %1013, %shuffleResult_572 : vector<1xf32>
          %shuffleResult_574, %valid_575 = gpu.shuffle  xor %1014, %c4_i32, %c64_i32 : vector<1xf32>
          %1015 = arith.addf %1014, %shuffleResult_574 : vector<1xf32>
          %shuffleResult_576, %valid_577 = gpu.shuffle  xor %1015, %c8_i32, %c64_i32 : vector<1xf32>
          %1016 = arith.addf %1015, %shuffleResult_576 : vector<1xf32>
          %shuffleResult_578, %valid_579 = gpu.shuffle  xor %1016, %c16_i32, %c64_i32 : vector<1xf32>
          %1017 = arith.addf %1016, %shuffleResult_578 : vector<1xf32>
          %shuffleResult_580, %valid_581 = gpu.shuffle  xor %1017, %c32_i32, %c64_i32 : vector<1xf32>
          %1018 = arith.addf %1017, %shuffleResult_580 : vector<1xf32>
          %1019 = arith.addf %1018, %539 : vector<1xf32>
          %1020 = arith.extf %255 : f16 to f32
          %1021 = arith.mulf %1020, %560 : f32
          %1022 = vector.splat %1021 : vector<1xf32>
          %shuffleResult_582, %valid_583 = gpu.shuffle  xor %1022, %c1_i32, %c64_i32 : vector<1xf32>
          %1023 = arith.addf %1022, %shuffleResult_582 : vector<1xf32>
          %shuffleResult_584, %valid_585 = gpu.shuffle  xor %1023, %c2_i32, %c64_i32 : vector<1xf32>
          %1024 = arith.addf %1023, %shuffleResult_584 : vector<1xf32>
          %shuffleResult_586, %valid_587 = gpu.shuffle  xor %1024, %c4_i32, %c64_i32 : vector<1xf32>
          %1025 = arith.addf %1024, %shuffleResult_586 : vector<1xf32>
          %shuffleResult_588, %valid_589 = gpu.shuffle  xor %1025, %c8_i32, %c64_i32 : vector<1xf32>
          %1026 = arith.addf %1025, %shuffleResult_588 : vector<1xf32>
          %shuffleResult_590, %valid_591 = gpu.shuffle  xor %1026, %c16_i32, %c64_i32 : vector<1xf32>
          %1027 = arith.addf %1026, %shuffleResult_590 : vector<1xf32>
          %shuffleResult_592, %valid_593 = gpu.shuffle  xor %1027, %c32_i32, %c64_i32 : vector<1xf32>
          %1028 = arith.addf %1027, %shuffleResult_592 : vector<1xf32>
          %1029 = arith.addf %1028, %540 : vector<1xf32>
          %1030 = arith.extf %256 : f16 to f32
          %1031 = arith.mulf %1030, %560 : f32
          %1032 = vector.splat %1031 : vector<1xf32>
          %shuffleResult_594, %valid_595 = gpu.shuffle  xor %1032, %c1_i32, %c64_i32 : vector<1xf32>
          %1033 = arith.addf %1032, %shuffleResult_594 : vector<1xf32>
          %shuffleResult_596, %valid_597 = gpu.shuffle  xor %1033, %c2_i32, %c64_i32 : vector<1xf32>
          %1034 = arith.addf %1033, %shuffleResult_596 : vector<1xf32>
          %shuffleResult_598, %valid_599 = gpu.shuffle  xor %1034, %c4_i32, %c64_i32 : vector<1xf32>
          %1035 = arith.addf %1034, %shuffleResult_598 : vector<1xf32>
          %shuffleResult_600, %valid_601 = gpu.shuffle  xor %1035, %c8_i32, %c64_i32 : vector<1xf32>
          %1036 = arith.addf %1035, %shuffleResult_600 : vector<1xf32>
          %shuffleResult_602, %valid_603 = gpu.shuffle  xor %1036, %c16_i32, %c64_i32 : vector<1xf32>
          %1037 = arith.addf %1036, %shuffleResult_602 : vector<1xf32>
          %shuffleResult_604, %valid_605 = gpu.shuffle  xor %1037, %c32_i32, %c64_i32 : vector<1xf32>
          %1038 = arith.addf %1037, %shuffleResult_604 : vector<1xf32>
          %1039 = arith.addf %1038, %541 : vector<1xf32>
          %1040 = arith.extf %257 : f16 to f32
          %1041 = arith.mulf %1040, %560 : f32
          %1042 = vector.splat %1041 : vector<1xf32>
          %shuffleResult_606, %valid_607 = gpu.shuffle  xor %1042, %c1_i32, %c64_i32 : vector<1xf32>
          %1043 = arith.addf %1042, %shuffleResult_606 : vector<1xf32>
          %shuffleResult_608, %valid_609 = gpu.shuffle  xor %1043, %c2_i32, %c64_i32 : vector<1xf32>
          %1044 = arith.addf %1043, %shuffleResult_608 : vector<1xf32>
          %shuffleResult_610, %valid_611 = gpu.shuffle  xor %1044, %c4_i32, %c64_i32 : vector<1xf32>
          %1045 = arith.addf %1044, %shuffleResult_610 : vector<1xf32>
          %shuffleResult_612, %valid_613 = gpu.shuffle  xor %1045, %c8_i32, %c64_i32 : vector<1xf32>
          %1046 = arith.addf %1045, %shuffleResult_612 : vector<1xf32>
          %shuffleResult_614, %valid_615 = gpu.shuffle  xor %1046, %c16_i32, %c64_i32 : vector<1xf32>
          %1047 = arith.addf %1046, %shuffleResult_614 : vector<1xf32>
          %shuffleResult_616, %valid_617 = gpu.shuffle  xor %1047, %c32_i32, %c64_i32 : vector<1xf32>
          %1048 = arith.addf %1047, %shuffleResult_616 : vector<1xf32>
          %1049 = arith.addf %1048, %542 : vector<1xf32>
          %1050 = arith.extf %258 : f16 to f32
          %1051 = arith.mulf %1050, %560 : f32
          %1052 = vector.splat %1051 : vector<1xf32>
          %shuffleResult_618, %valid_619 = gpu.shuffle  xor %1052, %c1_i32, %c64_i32 : vector<1xf32>
          %1053 = arith.addf %1052, %shuffleResult_618 : vector<1xf32>
          %shuffleResult_620, %valid_621 = gpu.shuffle  xor %1053, %c2_i32, %c64_i32 : vector<1xf32>
          %1054 = arith.addf %1053, %shuffleResult_620 : vector<1xf32>
          %shuffleResult_622, %valid_623 = gpu.shuffle  xor %1054, %c4_i32, %c64_i32 : vector<1xf32>
          %1055 = arith.addf %1054, %shuffleResult_622 : vector<1xf32>
          %shuffleResult_624, %valid_625 = gpu.shuffle  xor %1055, %c8_i32, %c64_i32 : vector<1xf32>
          %1056 = arith.addf %1055, %shuffleResult_624 : vector<1xf32>
          %shuffleResult_626, %valid_627 = gpu.shuffle  xor %1056, %c16_i32, %c64_i32 : vector<1xf32>
          %1057 = arith.addf %1056, %shuffleResult_626 : vector<1xf32>
          %shuffleResult_628, %valid_629 = gpu.shuffle  xor %1057, %c32_i32, %c64_i32 : vector<1xf32>
          %1058 = arith.addf %1057, %shuffleResult_628 : vector<1xf32>
          %1059 = arith.addf %1058, %543 : vector<1xf32>
          %1060 = arith.extf %259 : f16 to f32
          %1061 = arith.mulf %1060, %560 : f32
          %1062 = vector.splat %1061 : vector<1xf32>
          %shuffleResult_630, %valid_631 = gpu.shuffle  xor %1062, %c1_i32, %c64_i32 : vector<1xf32>
          %1063 = arith.addf %1062, %shuffleResult_630 : vector<1xf32>
          %shuffleResult_632, %valid_633 = gpu.shuffle  xor %1063, %c2_i32, %c64_i32 : vector<1xf32>
          %1064 = arith.addf %1063, %shuffleResult_632 : vector<1xf32>
          %shuffleResult_634, %valid_635 = gpu.shuffle  xor %1064, %c4_i32, %c64_i32 : vector<1xf32>
          %1065 = arith.addf %1064, %shuffleResult_634 : vector<1xf32>
          %shuffleResult_636, %valid_637 = gpu.shuffle  xor %1065, %c8_i32, %c64_i32 : vector<1xf32>
          %1066 = arith.addf %1065, %shuffleResult_636 : vector<1xf32>
          %shuffleResult_638, %valid_639 = gpu.shuffle  xor %1066, %c16_i32, %c64_i32 : vector<1xf32>
          %1067 = arith.addf %1066, %shuffleResult_638 : vector<1xf32>
          %shuffleResult_640, %valid_641 = gpu.shuffle  xor %1067, %c32_i32, %c64_i32 : vector<1xf32>
          %1068 = arith.addf %1067, %shuffleResult_640 : vector<1xf32>
          %1069 = arith.addf %1068, %544 : vector<1xf32>
          %1070 = arith.extf %260 : f16 to f32
          %1071 = arith.mulf %1070, %560 : f32
          %1072 = vector.splat %1071 : vector<1xf32>
          %shuffleResult_642, %valid_643 = gpu.shuffle  xor %1072, %c1_i32, %c64_i32 : vector<1xf32>
          %1073 = arith.addf %1072, %shuffleResult_642 : vector<1xf32>
          %shuffleResult_644, %valid_645 = gpu.shuffle  xor %1073, %c2_i32, %c64_i32 : vector<1xf32>
          %1074 = arith.addf %1073, %shuffleResult_644 : vector<1xf32>
          %shuffleResult_646, %valid_647 = gpu.shuffle  xor %1074, %c4_i32, %c64_i32 : vector<1xf32>
          %1075 = arith.addf %1074, %shuffleResult_646 : vector<1xf32>
          %shuffleResult_648, %valid_649 = gpu.shuffle  xor %1075, %c8_i32, %c64_i32 : vector<1xf32>
          %1076 = arith.addf %1075, %shuffleResult_648 : vector<1xf32>
          %shuffleResult_650, %valid_651 = gpu.shuffle  xor %1076, %c16_i32, %c64_i32 : vector<1xf32>
          %1077 = arith.addf %1076, %shuffleResult_650 : vector<1xf32>
          %shuffleResult_652, %valid_653 = gpu.shuffle  xor %1077, %c32_i32, %c64_i32 : vector<1xf32>
          %1078 = arith.addf %1077, %shuffleResult_652 : vector<1xf32>
          %1079 = arith.addf %1078, %545 : vector<1xf32>
          %1080 = arith.extf %261 : f16 to f32
          %1081 = arith.mulf %1080, %560 : f32
          %1082 = vector.splat %1081 : vector<1xf32>
          %shuffleResult_654, %valid_655 = gpu.shuffle  xor %1082, %c1_i32, %c64_i32 : vector<1xf32>
          %1083 = arith.addf %1082, %shuffleResult_654 : vector<1xf32>
          %shuffleResult_656, %valid_657 = gpu.shuffle  xor %1083, %c2_i32, %c64_i32 : vector<1xf32>
          %1084 = arith.addf %1083, %shuffleResult_656 : vector<1xf32>
          %shuffleResult_658, %valid_659 = gpu.shuffle  xor %1084, %c4_i32, %c64_i32 : vector<1xf32>
          %1085 = arith.addf %1084, %shuffleResult_658 : vector<1xf32>
          %shuffleResult_660, %valid_661 = gpu.shuffle  xor %1085, %c8_i32, %c64_i32 : vector<1xf32>
          %1086 = arith.addf %1085, %shuffleResult_660 : vector<1xf32>
          %shuffleResult_662, %valid_663 = gpu.shuffle  xor %1086, %c16_i32, %c64_i32 : vector<1xf32>
          %1087 = arith.addf %1086, %shuffleResult_662 : vector<1xf32>
          %shuffleResult_664, %valid_665 = gpu.shuffle  xor %1087, %c32_i32, %c64_i32 : vector<1xf32>
          %1088 = arith.addf %1087, %shuffleResult_664 : vector<1xf32>
          %1089 = arith.addf %1088, %546 : vector<1xf32>
          %1090 = arith.extf %262 : f16 to f32
          %1091 = arith.mulf %1090, %560 : f32
          %1092 = vector.splat %1091 : vector<1xf32>
          %shuffleResult_666, %valid_667 = gpu.shuffle  xor %1092, %c1_i32, %c64_i32 : vector<1xf32>
          %1093 = arith.addf %1092, %shuffleResult_666 : vector<1xf32>
          %shuffleResult_668, %valid_669 = gpu.shuffle  xor %1093, %c2_i32, %c64_i32 : vector<1xf32>
          %1094 = arith.addf %1093, %shuffleResult_668 : vector<1xf32>
          %shuffleResult_670, %valid_671 = gpu.shuffle  xor %1094, %c4_i32, %c64_i32 : vector<1xf32>
          %1095 = arith.addf %1094, %shuffleResult_670 : vector<1xf32>
          %shuffleResult_672, %valid_673 = gpu.shuffle  xor %1095, %c8_i32, %c64_i32 : vector<1xf32>
          %1096 = arith.addf %1095, %shuffleResult_672 : vector<1xf32>
          %shuffleResult_674, %valid_675 = gpu.shuffle  xor %1096, %c16_i32, %c64_i32 : vector<1xf32>
          %1097 = arith.addf %1096, %shuffleResult_674 : vector<1xf32>
          %shuffleResult_676, %valid_677 = gpu.shuffle  xor %1097, %c32_i32, %c64_i32 : vector<1xf32>
          %1098 = arith.addf %1097, %shuffleResult_676 : vector<1xf32>
          %1099 = arith.addf %1098, %547 : vector<1xf32>
          %1100 = arith.extf %263 : f16 to f32
          %1101 = arith.mulf %1100, %560 : f32
          %1102 = vector.splat %1101 : vector<1xf32>
          %shuffleResult_678, %valid_679 = gpu.shuffle  xor %1102, %c1_i32, %c64_i32 : vector<1xf32>
          %1103 = arith.addf %1102, %shuffleResult_678 : vector<1xf32>
          %shuffleResult_680, %valid_681 = gpu.shuffle  xor %1103, %c2_i32, %c64_i32 : vector<1xf32>
          %1104 = arith.addf %1103, %shuffleResult_680 : vector<1xf32>
          %shuffleResult_682, %valid_683 = gpu.shuffle  xor %1104, %c4_i32, %c64_i32 : vector<1xf32>
          %1105 = arith.addf %1104, %shuffleResult_682 : vector<1xf32>
          %shuffleResult_684, %valid_685 = gpu.shuffle  xor %1105, %c8_i32, %c64_i32 : vector<1xf32>
          %1106 = arith.addf %1105, %shuffleResult_684 : vector<1xf32>
          %shuffleResult_686, %valid_687 = gpu.shuffle  xor %1106, %c16_i32, %c64_i32 : vector<1xf32>
          %1107 = arith.addf %1106, %shuffleResult_686 : vector<1xf32>
          %shuffleResult_688, %valid_689 = gpu.shuffle  xor %1107, %c32_i32, %c64_i32 : vector<1xf32>
          %1108 = arith.addf %1107, %shuffleResult_688 : vector<1xf32>
          %1109 = arith.addf %1108, %548 : vector<1xf32>
          %1110 = arith.extf %264 : f16 to f32
          %1111 = arith.mulf %1110, %560 : f32
          %1112 = vector.splat %1111 : vector<1xf32>
          %shuffleResult_690, %valid_691 = gpu.shuffle  xor %1112, %c1_i32, %c64_i32 : vector<1xf32>
          %1113 = arith.addf %1112, %shuffleResult_690 : vector<1xf32>
          %shuffleResult_692, %valid_693 = gpu.shuffle  xor %1113, %c2_i32, %c64_i32 : vector<1xf32>
          %1114 = arith.addf %1113, %shuffleResult_692 : vector<1xf32>
          %shuffleResult_694, %valid_695 = gpu.shuffle  xor %1114, %c4_i32, %c64_i32 : vector<1xf32>
          %1115 = arith.addf %1114, %shuffleResult_694 : vector<1xf32>
          %shuffleResult_696, %valid_697 = gpu.shuffle  xor %1115, %c8_i32, %c64_i32 : vector<1xf32>
          %1116 = arith.addf %1115, %shuffleResult_696 : vector<1xf32>
          %shuffleResult_698, %valid_699 = gpu.shuffle  xor %1116, %c16_i32, %c64_i32 : vector<1xf32>
          %1117 = arith.addf %1116, %shuffleResult_698 : vector<1xf32>
          %shuffleResult_700, %valid_701 = gpu.shuffle  xor %1117, %c32_i32, %c64_i32 : vector<1xf32>
          %1118 = arith.addf %1117, %shuffleResult_700 : vector<1xf32>
          %1119 = arith.addf %1118, %549 : vector<1xf32>
          %1120 = arith.extf %265 : f16 to f32
          %1121 = arith.mulf %1120, %560 : f32
          %1122 = vector.splat %1121 : vector<1xf32>
          %shuffleResult_702, %valid_703 = gpu.shuffle  xor %1122, %c1_i32, %c64_i32 : vector<1xf32>
          %1123 = arith.addf %1122, %shuffleResult_702 : vector<1xf32>
          %shuffleResult_704, %valid_705 = gpu.shuffle  xor %1123, %c2_i32, %c64_i32 : vector<1xf32>
          %1124 = arith.addf %1123, %shuffleResult_704 : vector<1xf32>
          %shuffleResult_706, %valid_707 = gpu.shuffle  xor %1124, %c4_i32, %c64_i32 : vector<1xf32>
          %1125 = arith.addf %1124, %shuffleResult_706 : vector<1xf32>
          %shuffleResult_708, %valid_709 = gpu.shuffle  xor %1125, %c8_i32, %c64_i32 : vector<1xf32>
          %1126 = arith.addf %1125, %shuffleResult_708 : vector<1xf32>
          %shuffleResult_710, %valid_711 = gpu.shuffle  xor %1126, %c16_i32, %c64_i32 : vector<1xf32>
          %1127 = arith.addf %1126, %shuffleResult_710 : vector<1xf32>
          %shuffleResult_712, %valid_713 = gpu.shuffle  xor %1127, %c32_i32, %c64_i32 : vector<1xf32>
          %1128 = arith.addf %1127, %shuffleResult_712 : vector<1xf32>
          %1129 = arith.addf %1128, %550 : vector<1xf32>
          %1130 = arith.extf %266 : f16 to f32
          %1131 = arith.mulf %1130, %560 : f32
          %1132 = vector.splat %1131 : vector<1xf32>
          %shuffleResult_714, %valid_715 = gpu.shuffle  xor %1132, %c1_i32, %c64_i32 : vector<1xf32>
          %1133 = arith.addf %1132, %shuffleResult_714 : vector<1xf32>
          %shuffleResult_716, %valid_717 = gpu.shuffle  xor %1133, %c2_i32, %c64_i32 : vector<1xf32>
          %1134 = arith.addf %1133, %shuffleResult_716 : vector<1xf32>
          %shuffleResult_718, %valid_719 = gpu.shuffle  xor %1134, %c4_i32, %c64_i32 : vector<1xf32>
          %1135 = arith.addf %1134, %shuffleResult_718 : vector<1xf32>
          %shuffleResult_720, %valid_721 = gpu.shuffle  xor %1135, %c8_i32, %c64_i32 : vector<1xf32>
          %1136 = arith.addf %1135, %shuffleResult_720 : vector<1xf32>
          %shuffleResult_722, %valid_723 = gpu.shuffle  xor %1136, %c16_i32, %c64_i32 : vector<1xf32>
          %1137 = arith.addf %1136, %shuffleResult_722 : vector<1xf32>
          %shuffleResult_724, %valid_725 = gpu.shuffle  xor %1137, %c32_i32, %c64_i32 : vector<1xf32>
          %1138 = arith.addf %1137, %shuffleResult_724 : vector<1xf32>
          %1139 = arith.addf %1138, %551 : vector<1xf32>
          %1140 = arith.extf %267 : f16 to f32
          %1141 = arith.mulf %1140, %560 : f32
          %1142 = vector.splat %1141 : vector<1xf32>
          %shuffleResult_726, %valid_727 = gpu.shuffle  xor %1142, %c1_i32, %c64_i32 : vector<1xf32>
          %1143 = arith.addf %1142, %shuffleResult_726 : vector<1xf32>
          %shuffleResult_728, %valid_729 = gpu.shuffle  xor %1143, %c2_i32, %c64_i32 : vector<1xf32>
          %1144 = arith.addf %1143, %shuffleResult_728 : vector<1xf32>
          %shuffleResult_730, %valid_731 = gpu.shuffle  xor %1144, %c4_i32, %c64_i32 : vector<1xf32>
          %1145 = arith.addf %1144, %shuffleResult_730 : vector<1xf32>
          %shuffleResult_732, %valid_733 = gpu.shuffle  xor %1145, %c8_i32, %c64_i32 : vector<1xf32>
          %1146 = arith.addf %1145, %shuffleResult_732 : vector<1xf32>
          %shuffleResult_734, %valid_735 = gpu.shuffle  xor %1146, %c16_i32, %c64_i32 : vector<1xf32>
          %1147 = arith.addf %1146, %shuffleResult_734 : vector<1xf32>
          %shuffleResult_736, %valid_737 = gpu.shuffle  xor %1147, %c32_i32, %c64_i32 : vector<1xf32>
          %1148 = arith.addf %1147, %shuffleResult_736 : vector<1xf32>
          %1149 = arith.addf %1148, %552 : vector<1xf32>
          %1150 = arith.extf %268 : f16 to f32
          %1151 = arith.mulf %1150, %560 : f32
          %1152 = vector.splat %1151 : vector<1xf32>
          %shuffleResult_738, %valid_739 = gpu.shuffle  xor %1152, %c1_i32, %c64_i32 : vector<1xf32>
          %1153 = arith.addf %1152, %shuffleResult_738 : vector<1xf32>
          %shuffleResult_740, %valid_741 = gpu.shuffle  xor %1153, %c2_i32, %c64_i32 : vector<1xf32>
          %1154 = arith.addf %1153, %shuffleResult_740 : vector<1xf32>
          %shuffleResult_742, %valid_743 = gpu.shuffle  xor %1154, %c4_i32, %c64_i32 : vector<1xf32>
          %1155 = arith.addf %1154, %shuffleResult_742 : vector<1xf32>
          %shuffleResult_744, %valid_745 = gpu.shuffle  xor %1155, %c8_i32, %c64_i32 : vector<1xf32>
          %1156 = arith.addf %1155, %shuffleResult_744 : vector<1xf32>
          %shuffleResult_746, %valid_747 = gpu.shuffle  xor %1156, %c16_i32, %c64_i32 : vector<1xf32>
          %1157 = arith.addf %1156, %shuffleResult_746 : vector<1xf32>
          %shuffleResult_748, %valid_749 = gpu.shuffle  xor %1157, %c32_i32, %c64_i32 : vector<1xf32>
          %1158 = arith.addf %1157, %shuffleResult_748 : vector<1xf32>
          %1159 = arith.addf %1158, %553 : vector<1xf32>
          %1160 = arith.extf %269 : f16 to f32
          %1161 = arith.mulf %1160, %560 : f32
          %1162 = vector.splat %1161 : vector<1xf32>
          %shuffleResult_750, %valid_751 = gpu.shuffle  xor %1162, %c1_i32, %c64_i32 : vector<1xf32>
          %1163 = arith.addf %1162, %shuffleResult_750 : vector<1xf32>
          %shuffleResult_752, %valid_753 = gpu.shuffle  xor %1163, %c2_i32, %c64_i32 : vector<1xf32>
          %1164 = arith.addf %1163, %shuffleResult_752 : vector<1xf32>
          %shuffleResult_754, %valid_755 = gpu.shuffle  xor %1164, %c4_i32, %c64_i32 : vector<1xf32>
          %1165 = arith.addf %1164, %shuffleResult_754 : vector<1xf32>
          %shuffleResult_756, %valid_757 = gpu.shuffle  xor %1165, %c8_i32, %c64_i32 : vector<1xf32>
          %1166 = arith.addf %1165, %shuffleResult_756 : vector<1xf32>
          %shuffleResult_758, %valid_759 = gpu.shuffle  xor %1166, %c16_i32, %c64_i32 : vector<1xf32>
          %1167 = arith.addf %1166, %shuffleResult_758 : vector<1xf32>
          %shuffleResult_760, %valid_761 = gpu.shuffle  xor %1167, %c32_i32, %c64_i32 : vector<1xf32>
          %1168 = arith.addf %1167, %shuffleResult_760 : vector<1xf32>
          %1169 = arith.addf %1168, %554 : vector<1xf32>
          %1170 = arith.extf %270 : f16 to f32
          %1171 = arith.mulf %1170, %560 : f32
          %1172 = vector.splat %1171 : vector<1xf32>
          %shuffleResult_762, %valid_763 = gpu.shuffle  xor %1172, %c1_i32, %c64_i32 : vector<1xf32>
          %1173 = arith.addf %1172, %shuffleResult_762 : vector<1xf32>
          %shuffleResult_764, %valid_765 = gpu.shuffle  xor %1173, %c2_i32, %c64_i32 : vector<1xf32>
          %1174 = arith.addf %1173, %shuffleResult_764 : vector<1xf32>
          %shuffleResult_766, %valid_767 = gpu.shuffle  xor %1174, %c4_i32, %c64_i32 : vector<1xf32>
          %1175 = arith.addf %1174, %shuffleResult_766 : vector<1xf32>
          %shuffleResult_768, %valid_769 = gpu.shuffle  xor %1175, %c8_i32, %c64_i32 : vector<1xf32>
          %1176 = arith.addf %1175, %shuffleResult_768 : vector<1xf32>
          %shuffleResult_770, %valid_771 = gpu.shuffle  xor %1176, %c16_i32, %c64_i32 : vector<1xf32>
          %1177 = arith.addf %1176, %shuffleResult_770 : vector<1xf32>
          %shuffleResult_772, %valid_773 = gpu.shuffle  xor %1177, %c32_i32, %c64_i32 : vector<1xf32>
          %1178 = arith.addf %1177, %shuffleResult_772 : vector<1xf32>
          %1179 = arith.addf %1178, %555 : vector<1xf32>
          %1180 = arith.extf %271 : f16 to f32
          %1181 = arith.mulf %1180, %560 : f32
          %1182 = vector.splat %1181 : vector<1xf32>
          %shuffleResult_774, %valid_775 = gpu.shuffle  xor %1182, %c1_i32, %c64_i32 : vector<1xf32>
          %1183 = arith.addf %1182, %shuffleResult_774 : vector<1xf32>
          %shuffleResult_776, %valid_777 = gpu.shuffle  xor %1183, %c2_i32, %c64_i32 : vector<1xf32>
          %1184 = arith.addf %1183, %shuffleResult_776 : vector<1xf32>
          %shuffleResult_778, %valid_779 = gpu.shuffle  xor %1184, %c4_i32, %c64_i32 : vector<1xf32>
          %1185 = arith.addf %1184, %shuffleResult_778 : vector<1xf32>
          %shuffleResult_780, %valid_781 = gpu.shuffle  xor %1185, %c8_i32, %c64_i32 : vector<1xf32>
          %1186 = arith.addf %1185, %shuffleResult_780 : vector<1xf32>
          %shuffleResult_782, %valid_783 = gpu.shuffle  xor %1186, %c16_i32, %c64_i32 : vector<1xf32>
          %1187 = arith.addf %1186, %shuffleResult_782 : vector<1xf32>
          %shuffleResult_784, %valid_785 = gpu.shuffle  xor %1187, %c32_i32, %c64_i32 : vector<1xf32>
          %1188 = arith.addf %1187, %shuffleResult_784 : vector<1xf32>
          %1189 = arith.addf %1188, %556 : vector<1xf32>
          %1190 = arith.extf %272 : f16 to f32
          %1191 = arith.mulf %1190, %560 : f32
          %1192 = vector.splat %1191 : vector<1xf32>
          %shuffleResult_786, %valid_787 = gpu.shuffle  xor %1192, %c1_i32, %c64_i32 : vector<1xf32>
          %1193 = arith.addf %1192, %shuffleResult_786 : vector<1xf32>
          %shuffleResult_788, %valid_789 = gpu.shuffle  xor %1193, %c2_i32, %c64_i32 : vector<1xf32>
          %1194 = arith.addf %1193, %shuffleResult_788 : vector<1xf32>
          %shuffleResult_790, %valid_791 = gpu.shuffle  xor %1194, %c4_i32, %c64_i32 : vector<1xf32>
          %1195 = arith.addf %1194, %shuffleResult_790 : vector<1xf32>
          %shuffleResult_792, %valid_793 = gpu.shuffle  xor %1195, %c8_i32, %c64_i32 : vector<1xf32>
          %1196 = arith.addf %1195, %shuffleResult_792 : vector<1xf32>
          %shuffleResult_794, %valid_795 = gpu.shuffle  xor %1196, %c16_i32, %c64_i32 : vector<1xf32>
          %1197 = arith.addf %1196, %shuffleResult_794 : vector<1xf32>
          %shuffleResult_796, %valid_797 = gpu.shuffle  xor %1197, %c32_i32, %c64_i32 : vector<1xf32>
          %1198 = arith.addf %1197, %shuffleResult_796 : vector<1xf32>
          %1199 = arith.addf %1198, %557 : vector<1xf32>
          scf.yield %478, %492, %569, %579, %589, %599, %609, %619, %629, %639, %649, %659, %669, %679, %689, %699, %709, %719, %729, %739, %749, %759, %769, %779, %789, %799, %809, %819, %829, %839, %849, %859, %869, %879, %889, %899, %909, %919, %929, %939, %949, %959, %969, %979, %989, %999, %1009, %1019, %1029, %1039, %1049, %1059, %1069, %1079, %1089, %1099, %1109, %1119, %1129, %1139, %1149, %1159, %1169, %1179, %1189, %1199 : vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>, vector<1xf32>
        }
        %74 = arith.cmpi sgt, %23, %c0 : index
        scf.if %74 {
          %75 = stream.binding.subspan %arg6[%c0] : !stream.binding -> memref<8x?x16xf32, strided<[?, 16, 1], offset: ?>>{%arg9}
          %76 = stream.binding.subspan %arg5[%c0] : !stream.binding -> memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>{%arg9}
          %77 = arith.divf %cst_3, %73#1 : vector<1xf32>
          %78 = arith.mulf %73#2, %77 : vector<1xf32>
          %79 = arith.mulf %73#3, %77 : vector<1xf32>
          %80 = arith.mulf %73#4, %77 : vector<1xf32>
          %81 = arith.mulf %73#5, %77 : vector<1xf32>
          %82 = arith.mulf %73#6, %77 : vector<1xf32>
          %83 = arith.mulf %73#7, %77 : vector<1xf32>
          %84 = arith.mulf %73#8, %77 : vector<1xf32>
          %85 = arith.mulf %73#9, %77 : vector<1xf32>
          %86 = arith.mulf %73#10, %77 : vector<1xf32>
          %87 = arith.mulf %73#11, %77 : vector<1xf32>
          %88 = arith.mulf %73#12, %77 : vector<1xf32>
          %89 = arith.mulf %73#13, %77 : vector<1xf32>
          %90 = arith.mulf %73#14, %77 : vector<1xf32>
          %91 = arith.mulf %73#15, %77 : vector<1xf32>
          %92 = arith.mulf %73#16, %77 : vector<1xf32>
          %93 = arith.mulf %73#17, %77 : vector<1xf32>
          %94 = arith.mulf %73#18, %77 : vector<1xf32>
          %95 = arith.mulf %73#19, %77 : vector<1xf32>
          %96 = arith.mulf %73#20, %77 : vector<1xf32>
          %97 = arith.mulf %73#21, %77 : vector<1xf32>
          %98 = arith.mulf %73#22, %77 : vector<1xf32>
          %99 = arith.mulf %73#23, %77 : vector<1xf32>
          %100 = arith.mulf %73#24, %77 : vector<1xf32>
          %101 = arith.mulf %73#25, %77 : vector<1xf32>
          %102 = arith.mulf %73#26, %77 : vector<1xf32>
          %103 = arith.mulf %73#27, %77 : vector<1xf32>
          %104 = arith.mulf %73#28, %77 : vector<1xf32>
          %105 = arith.mulf %73#29, %77 : vector<1xf32>
          %106 = arith.mulf %73#30, %77 : vector<1xf32>
          %107 = arith.mulf %73#31, %77 : vector<1xf32>
          %108 = arith.mulf %73#32, %77 : vector<1xf32>
          %109 = arith.mulf %73#33, %77 : vector<1xf32>
          %110 = arith.mulf %73#34, %77 : vector<1xf32>
          %111 = arith.mulf %73#35, %77 : vector<1xf32>
          %112 = arith.mulf %73#36, %77 : vector<1xf32>
          %113 = arith.mulf %73#37, %77 : vector<1xf32>
          %114 = arith.mulf %73#38, %77 : vector<1xf32>
          %115 = arith.mulf %73#39, %77 : vector<1xf32>
          %116 = arith.mulf %73#40, %77 : vector<1xf32>
          %117 = arith.mulf %73#41, %77 : vector<1xf32>
          %118 = arith.mulf %73#42, %77 : vector<1xf32>
          %119 = arith.mulf %73#43, %77 : vector<1xf32>
          %120 = arith.mulf %73#44, %77 : vector<1xf32>
          %121 = arith.mulf %73#45, %77 : vector<1xf32>
          %122 = arith.mulf %73#46, %77 : vector<1xf32>
          %123 = arith.mulf %73#47, %77 : vector<1xf32>
          %124 = arith.mulf %73#48, %77 : vector<1xf32>
          %125 = arith.mulf %73#49, %77 : vector<1xf32>
          %126 = arith.mulf %73#50, %77 : vector<1xf32>
          %127 = arith.mulf %73#51, %77 : vector<1xf32>
          %128 = arith.mulf %73#52, %77 : vector<1xf32>
          %129 = arith.mulf %73#53, %77 : vector<1xf32>
          %130 = arith.mulf %73#54, %77 : vector<1xf32>
          %131 = arith.mulf %73#55, %77 : vector<1xf32>
          %132 = arith.mulf %73#56, %77 : vector<1xf32>
          %133 = arith.mulf %73#57, %77 : vector<1xf32>
          %134 = arith.mulf %73#58, %77 : vector<1xf32>
          %135 = arith.mulf %73#59, %77 : vector<1xf32>
          %136 = arith.mulf %73#60, %77 : vector<1xf32>
          %137 = arith.mulf %73#61, %77 : vector<1xf32>
          %138 = arith.mulf %73#62, %77 : vector<1xf32>
          %139 = arith.mulf %73#63, %77 : vector<1xf32>
          %140 = arith.mulf %73#64, %77 : vector<1xf32>
          %141 = arith.mulf %73#65, %77 : vector<1xf32>
          %142 = math.log2 %73#1 : vector<1xf32>
          %143 = arith.addf %73#0, %142 : vector<1xf32>
          vector.store %143, %75[%block_id_z, %block_id_x, %block_id_y] : memref<8x?x16xf32, strided<[?, 16, 1], offset: ?>>, vector<1xf32>
          vector.store %78, %76[%block_id_z, %block_id_x, %block_id_y, %c0] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %79, %76[%block_id_z, %block_id_x, %block_id_y, %c1] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %80, %76[%block_id_z, %block_id_x, %block_id_y, %c2] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %81, %76[%block_id_z, %block_id_x, %block_id_y, %c3] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %82, %76[%block_id_z, %block_id_x, %block_id_y, %c4] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %83, %76[%block_id_z, %block_id_x, %block_id_y, %c5] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %84, %76[%block_id_z, %block_id_x, %block_id_y, %c6] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %85, %76[%block_id_z, %block_id_x, %block_id_y, %c7] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %86, %76[%block_id_z, %block_id_x, %block_id_y, %c8] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %87, %76[%block_id_z, %block_id_x, %block_id_y, %c9] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %88, %76[%block_id_z, %block_id_x, %block_id_y, %c10] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %89, %76[%block_id_z, %block_id_x, %block_id_y, %c11] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %90, %76[%block_id_z, %block_id_x, %block_id_y, %c12] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %91, %76[%block_id_z, %block_id_x, %block_id_y, %c13] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %92, %76[%block_id_z, %block_id_x, %block_id_y, %c14] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %93, %76[%block_id_z, %block_id_x, %block_id_y, %c15] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %94, %76[%block_id_z, %block_id_x, %block_id_y, %c16] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %95, %76[%block_id_z, %block_id_x, %block_id_y, %c17] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %96, %76[%block_id_z, %block_id_x, %block_id_y, %c18] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %97, %76[%block_id_z, %block_id_x, %block_id_y, %c19] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %98, %76[%block_id_z, %block_id_x, %block_id_y, %c20] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %99, %76[%block_id_z, %block_id_x, %block_id_y, %c21] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %100, %76[%block_id_z, %block_id_x, %block_id_y, %c22] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %101, %76[%block_id_z, %block_id_x, %block_id_y, %c23] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %102, %76[%block_id_z, %block_id_x, %block_id_y, %c24] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %103, %76[%block_id_z, %block_id_x, %block_id_y, %c25] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %104, %76[%block_id_z, %block_id_x, %block_id_y, %c26] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %105, %76[%block_id_z, %block_id_x, %block_id_y, %c27] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %106, %76[%block_id_z, %block_id_x, %block_id_y, %c28] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %107, %76[%block_id_z, %block_id_x, %block_id_y, %c29] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %108, %76[%block_id_z, %block_id_x, %block_id_y, %c30] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %109, %76[%block_id_z, %block_id_x, %block_id_y, %c31] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %110, %76[%block_id_z, %block_id_x, %block_id_y, %c32] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %111, %76[%block_id_z, %block_id_x, %block_id_y, %c33] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %112, %76[%block_id_z, %block_id_x, %block_id_y, %c34] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %113, %76[%block_id_z, %block_id_x, %block_id_y, %c35] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %114, %76[%block_id_z, %block_id_x, %block_id_y, %c36] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %115, %76[%block_id_z, %block_id_x, %block_id_y, %c37] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %116, %76[%block_id_z, %block_id_x, %block_id_y, %c38] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %117, %76[%block_id_z, %block_id_x, %block_id_y, %c39] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %118, %76[%block_id_z, %block_id_x, %block_id_y, %c40] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %119, %76[%block_id_z, %block_id_x, %block_id_y, %c41] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %120, %76[%block_id_z, %block_id_x, %block_id_y, %c42] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %121, %76[%block_id_z, %block_id_x, %block_id_y, %c43] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %122, %76[%block_id_z, %block_id_x, %block_id_y, %c44] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %123, %76[%block_id_z, %block_id_x, %block_id_y, %c45] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %124, %76[%block_id_z, %block_id_x, %block_id_y, %c46] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %125, %76[%block_id_z, %block_id_x, %block_id_y, %c47] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %126, %76[%block_id_z, %block_id_x, %block_id_y, %c48] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %127, %76[%block_id_z, %block_id_x, %block_id_y, %c49] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %128, %76[%block_id_z, %block_id_x, %block_id_y, %c50] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %129, %76[%block_id_z, %block_id_x, %block_id_y, %c51] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %130, %76[%block_id_z, %block_id_x, %block_id_y, %c52] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %131, %76[%block_id_z, %block_id_x, %block_id_y, %c53] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %132, %76[%block_id_z, %block_id_x, %block_id_y, %c54] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %133, %76[%block_id_z, %block_id_x, %block_id_y, %c55] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %134, %76[%block_id_z, %block_id_x, %block_id_y, %c56] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %135, %76[%block_id_z, %block_id_x, %block_id_y, %c57] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %136, %76[%block_id_z, %block_id_x, %block_id_y, %c58] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %137, %76[%block_id_z, %block_id_x, %block_id_y, %c59] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %138, %76[%block_id_z, %block_id_x, %block_id_y, %c60] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %139, %76[%block_id_z, %block_id_x, %block_id_y, %c61] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %140, %76[%block_id_z, %block_id_x, %block_id_y, %c62] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
          vector.store %141, %76[%block_id_z, %block_id_x, %block_id_y, %c63] : memref<8x?x16x64xf32, strided<[?, 1024, 64, 1], offset: ?>>, vector<1xf32>
        }
        return
      }
    }
  }
  func.func @isolated_benchmark(%arg0: tensor<?x16x64xf16>, %arg1: tensor<?x16x64xf16>, %arg2: tensor<?x16x64xf16>, %arg3: tensor<?xi32>, %arg4: tensor<?xi32>, %arg5: tensor<8x?x16x64xf32>, %arg6: tensor<8x?x16xf32>, %arg7: index, %arg8: index, %arg9: index) -> (tensor<8x?x16x64xf32>, tensor<8x?x16xf32>) {
    %0:2 = flow.dispatch @phase_0::@phase_0[%arg7, %arg8, %arg9](%arg0, %arg1, %arg2, %arg3, %arg4, %arg5, %arg6, %arg7, %arg8, %arg9) : (tensor<?x16x64xf16>{%arg9}, tensor<?x16x64xf16>{%arg8}, tensor<?x16x64xf16>{%arg8}, tensor<?xi32>{%arg9}, tensor<?xi32>{%arg7}, tensor<8x?x16x64xf32>{%arg9}, tensor<8x?x16xf32>{%arg9}, index, index, index) -> (%arg5{%arg9}, %arg6{%arg9})
    return %0#0, %0#1 : tensor<8x?x16x64xf32>, tensor<8x?x16xf32>
  }
}
